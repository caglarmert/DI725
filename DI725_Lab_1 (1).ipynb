{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3745686a-405f-4729-a239-ffd17f6c5087",
      "metadata": {
        "id": "3745686a-405f-4729-a239-ffd17f6c5087"
      },
      "source": [
        "# DI 725: Transformers and Attention-Based Deep Networks\n",
        "\n",
        "## An End-to-End Tutorial for Implementing Transformers\n",
        "\n",
        "The purpose of this notebook is to introduce the transformers architecture, building different types of transformers and its adaptations to various tasks.\n",
        "\n",
        "In this notebook, there will be three different tasks, suitable to demonstrate Encoder-Transformer, Decoder-Transformer and Encoder-Decoder Transformer architectures.\n",
        "\n",
        "### Authors:\n",
        "* Tuğba Taşkaya Temizel: ttemizel@metu.edu.tr\n",
        "* Alptekin Temizel: atemizel@metu.edu.tr\n",
        "* Ümit Mert Çağlar: mecaglar@metu.edu.tr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0f81a53-355d-456d-90d1-9b5432dd1ce7",
      "metadata": {
        "id": "c0f81a53-355d-456d-90d1-9b5432dd1ce7"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5125f78-dea0-4c0e-ab42-5978b7b2633e",
      "metadata": {
        "id": "c5125f78-dea0-4c0e-ab42-5978b7b2633e"
      },
      "source": [
        "## Attention Is All You Need\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/caglarmert/DI725/blob/main/src/attention_research_1.png?raw=true\" width=\"400\"/>\n",
        "</div>\n",
        "\n",
        "---\n",
        "Just by observing the architecture we can spot some important aspects of the Transformer architecture.\n",
        "* First, we have [embeddings](https://arxiv.org/abs/1608.05859) at the input and\n",
        "output, these are required in many tasks, to transform data into high dimensional vectors.\n",
        "* Second, we have [Positional Encoding](https://arxiv.org/pdf/1705.03122.pdf), which we require for the Transformer model to understand and relate the relative position of input and output tokens or embeddings.\n",
        "* On the left-hand side, we have the Encoder structure, which is a stacked network (depicted with Nx), that has the subcomponents of a Multi-Head Attention and a Feed Forward Network.\n",
        "* The attention mechanism, has Query, Key and Value (Q K V) as inputs, and all three of them are fed into the Multi-Head Attention block. This mechanism is the building pillar of Transformers, also highlighted by the authors:\n",
        " * *In this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output.*\n",
        " * *An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.*\n",
        "* We can also observe the Residual Connections and Layer Normalization block applied right after the attention and feed forward blocks. [Residual Connections](https://arxiv.org/abs/1512.03385) is an important factor that enables gradient flow in deeper networks. And [Layer Normalization](https://arxiv.org/abs/1607.06450) helps with the model training. Also the [Dropout](https://jmlr.org/papers/v15/srivastava14a.html) mechanism is applied for all sub-layers and it helps with the training.\n",
        "* Similarly on the right-hand side, we have another stacked architecture, but this time it is in the form of the Decoder structure.\n",
        "* The first attention mechanism we observe is ***Masked*** Multi-Head Self-Attention. It is masked to make sure that model only observes and attends to the previous tokens or embeddings.\n",
        "* The second attention mechanism in the Decoder architecture is Encoder-Decoder attention, or cross-attention layer. The keys and values come from the output of the Encoder stack while queries come from the first self-attention layer of the Decoder stack. With this cross-attention, decoder can attend over all positions in the input.\n",
        "* The Feed Forward layers, that are present in both Encoder and Decoder stacks, are defined by two linear layers and a ReLU activation function.\n",
        "* Finally, after all of the mechanisms and calculations, the generator that generates output probabilities is modeled by a linear layer and a softmax.\n",
        "\n",
        "---\n",
        "The following two outputs were generated by transformer models! The prompt for each answer was: \"Explain the transformers architecture to me, with brief details of each block\". Follow the links to read more on [OpenAI's ChatGPT](https://openai.com/blog/chatgpt) and [Google's Gemini](https://blog.google/technology/ai/google-gemini-ai/#introducing-gemini). Examining out of both Transformer models, we can clearly observe a refined and detailed answers!\n",
        "\n",
        "\n",
        "## ChatGPT\n",
        "\n",
        "### Transformer Architecture Overview\n",
        "\n",
        "The Transformer architecture revolutionized the field of natural language processing (NLP) by introducing a model that relies entirely on self-attention mechanisms, eliminating the need for recurrent or convolutional layers. Here's a brief overview of the main components of the Transformer architecture:\n",
        "\n",
        "#### 1. Input Embeddings\n",
        "- The input sequence, typically a sequence of word embeddings, is passed into the model. Each word is represented as a high-dimensional vector, often initialized randomly or pre-trained on a large corpus.\n",
        "\n",
        "#### 2. Positional Encoding\n",
        "- Since the Transformer doesn't inherently understand the order of tokens in a sequence, positional encodings are added to the input embeddings to provide information about token positions. These are usually sinusoidal functions of different frequencies and phases.\n",
        "\n",
        "#### 3. Encoder\n",
        "- The Encoder consists of multiple identical layers (usually 6-12). Each layer consists of two main sub-components:\n",
        "  - **Multi-Head Self-Attention Mechanism**: Computes attention weights between all pairs of words in the input sequence to capture relationships and dependencies among them.\n",
        "  - **Feedforward Neural Network**: Applies a fully connected feedforward network to each position separately and identically. It processes the output of the attention mechanism in a position-wise manner.\n",
        "\n",
        "#### 4. Decoder\n",
        "- The Decoder also consists of multiple identical layers (the same number as in the Encoder). Each layer in the Decoder has three main sub-components:\n",
        "  - **Masked Multi-Head Self-Attention Mechanism**: Similar to the Encoder's attention mechanism, but with a mask applied to prevent positions from attending to subsequent positions, ensuring that the model attends only to previous positions during generation.\n",
        "  - **Encoder-Decoder Attention Mechanism**: Allows the Decoder to focus on different parts of the input sequence (Encoder's output) by computing attention scores between the current position in the Decoder and all positions in the Encoder's output.\n",
        "  - **Feedforward Neural Network**: Similar to the Encoder, a fully connected feedforward network is applied to each position separately and identically.\n",
        "\n",
        "#### 5. Output Layer\n",
        "- The output of the final Decoder layer is passed through a linear layer followed by a softmax function to produce the probability distribution over the output vocabulary. During training, this distribution is compared to the actual target sequence using cross-entropy loss.\n",
        "\n",
        "#### 6. Loss Computation\n",
        "- The model's output is compared to the actual target sequence using cross-entropy loss. This comparison drives the learning process through backpropagation.\n",
        "\n",
        "The Transformer architecture's key innovation lies in its ability to capture long-range dependencies in sequences efficiently through self-attention mechanisms, making it highly parallelizable and scalable compared to traditional recurrent neural networks.\n",
        "\n",
        "---\n",
        "## Google's Gemini\n",
        "\n",
        "The Transformer architecture, introduced in the paper \"Attention is All You Need\", revolutionized natural language processing by relying solely on attention mechanisms instead of recurrent connections. Here's a breakdown of its key components:\n",
        "\n",
        "Overall Structure:\n",
        "\n",
        "An encoder processes the input sequence to capture its meaning.\n",
        "A decoder generates the output sequence based on the encoded representation and any additional context.\n",
        "Encoder and Decoder Blocks:\n",
        "\n",
        "Both the encoder and decoder consist of multiple identical encoder blocks and decoder blocks, respectively.\n",
        "Each block has two sub-blocks:\n",
        "Multi-head Self-attention: Captures relationships between elements within the sequence (encoder) or within the previously generated output (decoder).\n",
        "Feed-forward network: Adds non-linearity and complexity to the model.\n",
        "Residual connection and Layer Norm: Improve training stability and gradient flow.\n",
        "Key Details of Each Block:\n",
        "\n",
        "1. Multi-head Self-attention:\n",
        "\n",
        "Splits the input into queries, keys, and values.\n",
        "Computes attention scores based on the similarity between queries and keys.\n",
        "Masks out padded elements using attention masks.\n",
        "Aggregates values weighted by the attention scores, resulting in a context vector for each element.\n",
        "The \"multi-head\" part refers to performing this self-attention mechanism multiple times with different query and key projections, capturing diverse relationships.\n",
        "2. Feed-forward network:\n",
        "\n",
        "A two-layer network with ReLU activation for non-linearity.\n",
        "Adds complexity and allows the model to learn more intricate relationships.\n",
        "3. Residual connection and Layer Norm:\n",
        "\n",
        "Shortcuts around each sub-block are added to ensure the gradients can flow easily through the network.\n",
        "Layer normalization rescales and shifts the output of each sub-block, stabilizing the training process.\n",
        "Additional Components:\n",
        "\n",
        "Encoder-decoder attention: In a sequence-to-sequence setting, the decoder attends to the encoded representation in each block to incorporate context into the generated output.\n",
        "Positional encoding: Since the Transformer doesn't have inherent positional information, additional embeddings are added to encode the relative positions of elements in the sequence.\n",
        "Output layer: In the decoder, a final layer converts the internal representation into the final vocabulary probabilities for output generation.\n",
        "Benefits of Transformers:\n",
        "\n",
        "Parallelization: Attention allows for better parallelization during training compared to recurrent models.\n",
        "Long-range dependencies: Can capture long-range dependencies in sequences without relying on sequential processing.\n",
        "Adaptability: Can be applied to various NLP tasks with minor modifications.\n",
        "Drawbacks of Transformers:\n",
        "\n",
        "Computational cost: Attention can be computationally expensive, especially for long sequences.\n",
        "Memory intensive: Requires storing the entire input sequence for attention computations."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "In this part we import the required libraries. This part might be required to be operational on the Colab servers for later parts. It is advised to check the associated python requirements.txt, that is frozen at the time of preparation of this notebook, in case of any library or version error occurs while running this notebook. Mind that installing everything locally via pip install -r \"requirements.txt\" is not advised though, mainly because of the discrepancies between Colab and locally available machine."
      ],
      "metadata": {
        "id": "9bx_lEEFJI5N"
      },
      "id": "9bx_lEEFJI5N"
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment any install if needed. It is recommended that these installations\n",
        "# are performed prior to any notebook runs and imports\n",
        "\n",
        "# !pip install datasets # Huggingface dataset library\n",
        "# !pip install evaluate # Used for evaluation metrics\n",
        "# !pip install rouge_score # Is a text evaluation metric\n",
        "# !pip install trl #Transformers Reinforcement Learning framework\n",
        "# !pip install sacremoses # Used for specific characters, useful for languages like Turkish"
      ],
      "metadata": {
        "id": "yHryLjtEPxYd"
      },
      "id": "yHryLjtEPxYd",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "70a9b2e0-fdb5-4697-a48f-44d1a08503f8",
      "metadata": {
        "id": "70a9b2e0-fdb5-4697-a48f-44d1a08503f8"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The [torch](https://pytorch.org/) is a popular and diverse machine learning framework, enabling low level implementation (as low as it gets with Python anyway). The Neural Networks (nn) is a library within PyTorch that enables operations with neural network structures."
      ],
      "metadata": {
        "id": "QMDfs6xsJwj3"
      },
      "id": "QMDfs6xsJwj3"
    },
    {
      "cell_type": "markdown",
      "id": "1cce3f17-cf16-4b8e-be4c-769adba52eb2",
      "metadata": {
        "id": "1cce3f17-cf16-4b8e-be4c-769adba52eb2"
      },
      "source": [
        "# Building a Transformer Architecture in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Blocks\n",
        "Here we will try to build some building blocks that has some reusability."
      ],
      "metadata": {
        "id": "UXVW1LslAu9y"
      },
      "id": "UXVW1LslAu9y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.2: Positional Encoding\n",
        "\n",
        "Building the positional encoding can be observed from the implementation provided below.\n",
        "\n",
        "#### Instructions\n",
        "* Specify the PyTorch class that the positional encoder should subclass from.\n",
        "* Initialize a positional encoding matrix for token positions in sequences up to max_length.\n",
        "* Assign unique position encodings to the matrix pe by alternating the use of sine and cosine functions.\n",
        "* Update the input embeddings tensor x to add position information about the sequence using the positional encodings matrix.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "The Positional Encoding component is highlighted in the figure below, indicating its use, both in the Encoder, and the Decoder.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/caglarmert/DI725/blob/main/src/PE_highlight.png?raw=true\" width=\"400\"/>\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cCKhGMTXx-ss"
      },
      "id": "cCKhGMTXx-ss"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the __init__ method, we first initialize the superclass nn.Module and then define the model's dimension d_model and the maximum sequence length max_length. We then create a zero matrix pe of size max_length by d_model to store the positional encodings.\n",
        "\n",
        "Next, we calculate the positional encodings. We create a tensor position that contains the sequence positions and a tensor div_term that contains the division terms. The division terms are calculated using a formula that involves the natural logarithm of 10000 and the model's dimension. We then calculate the positional encodings by applying the sine function to the product of position and div_term for even indices and the cosine function for odd indices. The calculated positional encodings are then stored in the pe matrix.\n",
        "\n",
        "In the forward method, we add the positional encodings to the input embeddings tensor x. We slice the pe matrix to match the size of x before adding. The updated tensor x is then returned."
      ],
      "metadata": {
        "id": "6Xl4O79RK_bW"
      },
      "id": "6Xl4O79RK_bW"
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    r\"\"\"Inject some information about the relative or absolute position of the tokens in the sequence.\n",
        "        The positional encodings have the same dimension as the embeddings, so that the two can be summed.\n",
        "        Here, we use sine and cosine functions of different frequencies.\n",
        "    .. math:\n",
        "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
        "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
        "        \\text{where pos is the word position and i is the embed idx)\n",
        "    Args:\n",
        "        d_model: the embed dim (required).\n",
        "        dropout: the dropout value (default=0.1).\n",
        "        max_len: the max. length of the incoming sequence (default=5000).\n",
        "    Examples:\n",
        "        >>> pos_encoder = PositionalEncoding(d_model)\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        r\"\"\"Inputs of forward function\n",
        "        Args:\n",
        "            x: the sequence fed to the positional encoder model (required).\n",
        "        Shape:\n",
        "            x: [sequence length, batch size, embed dim]\n",
        "            output: [sequence length, batch size, embed dim]\n",
        "        Examples:\n",
        "            >>> output = pos_encoder(x)\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "ZFzC4clPGsP_"
      },
      "id": "ZFzC4clPGsP_",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To demonstrate the operation of Positional Encoding, we can use the following code block:"
      ],
      "metadata": {
        "id": "uKcRi-gdE8wf"
      },
      "id": "uKcRi-gdE8wf"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import altair as alt\n",
        "\n",
        "def example_positional():\n",
        "    pe = PositionalEncoding(20, 0, 5000)\n",
        "    y = pe.forward(torch.zeros(1, 100, 20))\n",
        "\n",
        "    data = pd.concat(\n",
        "        [\n",
        "            pd.DataFrame(\n",
        "                {\n",
        "                    \"embedding\": y[0, :, dim],\n",
        "                    \"dimension\": dim,\n",
        "                    \"position\": list(range(100)),\n",
        "                }\n",
        "            )\n",
        "            for dim in [4, 5, 6, 7]\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        alt.Chart(data)\n",
        "        .mark_line()\n",
        "        .properties(width=800)\n",
        "        .encode(x=\"position\", y=\"embedding\", color=\"dimension:N\")\n",
        "        .interactive()\n",
        "    )\n",
        "\n",
        "\n",
        "example_positional()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "ZKulvnac6xRb",
        "outputId": "0b6a05cd-21f9-4e96-bafe-1bf7f947d77d"
      },
      "id": "ZKulvnac6xRb",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<div id=\"altair-viz-2e0a69f778bc4ceea43473c027dcb93f\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-2e0a69f778bc4ceea43473c027dcb93f\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-2e0a69f778bc4ceea43473c027dcb93f\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-eafc635ddfa311c913cbcc2d2bc4477d\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"field\": \"dimension\", \"type\": \"nominal\"}, \"x\": {\"field\": \"position\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"embedding\", \"type\": \"quantitative\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-eafc635ddfa311c913cbcc2d2bc4477d\": [{\"embedding\": 0.0, \"dimension\": 4, \"position\": 0}, {\"embedding\": 0.15782663226127625, \"dimension\": 4, \"position\": 1}, {\"embedding\": 0.3116971552371979, \"dimension\": 4, \"position\": 2}, {\"embedding\": 0.45775455236434937, \"dimension\": 4, \"position\": 3}, {\"embedding\": 0.5923377275466919, \"dimension\": 4, \"position\": 4}, {\"embedding\": 0.7120732069015503, \"dimension\": 4, \"position\": 5}, {\"embedding\": 0.813959538936615, \"dimension\": 4, \"position\": 6}, {\"embedding\": 0.8954429626464844, \"dimension\": 4, \"position\": 7}, {\"embedding\": 0.9544808864593506, \"dimension\": 4, \"position\": 8}, {\"embedding\": 0.989593505859375, \"dimension\": 4, \"position\": 9}, {\"embedding\": 0.9999006390571594, \"dimension\": 4, \"position\": 10}, {\"embedding\": 0.9851439595222473, \"dimension\": 4, \"position\": 11}, {\"embedding\": 0.94569331407547, \"dimension\": 4, \"position\": 12}, {\"embedding\": 0.8825376033782959, \"dimension\": 4, \"position\": 13}, {\"embedding\": 0.7972599267959595, \"dimension\": 4, \"position\": 14}, {\"embedding\": 0.6919978260993958, \"dimension\": 4, \"position\": 15}, {\"embedding\": 0.5693899393081665, \"dimension\": 4, \"position\": 16}, {\"embedding\": 0.4325096309185028, \"dimension\": 4, \"position\": 17}, {\"embedding\": 0.284787654876709, \"dimension\": 4, \"position\": 18}, {\"embedding\": 0.12992730736732483, \"dimension\": 4, \"position\": 19}, {\"embedding\": -0.028190065175294876, \"dimension\": 4, \"position\": 20}, {\"embedding\": -0.18560057878494263, \"dimension\": 4, \"position\": 21}, {\"embedding\": -0.3383587896823883, \"dimension\": 4, \"position\": 22}, {\"embedding\": -0.4826357960700989, \"dimension\": 4, \"position\": 23}, {\"embedding\": -0.6148146390914917, \"dimension\": 4, \"position\": 24}, {\"embedding\": -0.7315824031829834, \"dimension\": 4, \"position\": 25}, {\"embedding\": -0.8300122618675232, \"dimension\": 4, \"position\": 26}, {\"embedding\": -0.9076365828514099, \"dimension\": 4, \"position\": 27}, {\"embedding\": -0.96250981092453, \"dimension\": 4, \"position\": 28}, {\"embedding\": -0.9932565093040466, \"dimension\": 4, \"position\": 29}, {\"embedding\": -0.9991058707237244, \"dimension\": 4, \"position\": 30}, {\"embedding\": -0.9799113273620605, \"dimension\": 4, \"position\": 31}, {\"embedding\": -0.9361540079116821, \"dimension\": 4, \"position\": 32}, {\"embedding\": -0.8689308166503906, \"dimension\": 4, \"position\": 33}, {\"embedding\": -0.7799267172813416, \"dimension\": 4, \"position\": 34}, {\"embedding\": -0.6713724136352539, \"dimension\": 4, \"position\": 35}, {\"embedding\": -0.5459895133972168, \"dimension\": 4, \"position\": 36}, {\"embedding\": -0.40692076086997986, \"dimension\": 4, \"position\": 37}, {\"embedding\": -0.2576519548892975, \"dimension\": 4, \"position\": 38}, {\"embedding\": -0.10192479938268661, \"dimension\": 4, \"position\": 39}, {\"embedding\": 0.056357722729444504, \"dimension\": 4, \"position\": 40}, {\"embedding\": 0.21322709321975708, \"dimension\": 4, \"position\": 41}, {\"embedding\": 0.3647516369819641, \"dimension\": 4, \"position\": 42}, {\"embedding\": 0.5071332454681396, \"dimension\": 4, \"position\": 43}, {\"embedding\": 0.6368028521537781, \"dimension\": 4, \"position\": 44}, {\"embedding\": 0.7505101561546326, \"dimension\": 4, \"position\": 45}, {\"embedding\": 0.8454052805900574, \"dimension\": 4, \"position\": 46}, {\"embedding\": 0.9191088080406189, \"dimension\": 4, \"position\": 47}, {\"embedding\": 0.9697737693786621, \"dimension\": 4, \"position\": 48}, {\"embedding\": 0.9961300492286682, \"dimension\": 4, \"position\": 49}, {\"embedding\": 0.9975170493125916, \"dimension\": 4, \"position\": 50}, {\"embedding\": 0.9738998413085938, \"dimension\": 4, \"position\": 51}, {\"embedding\": 0.9258706569671631, \"dimension\": 4, \"position\": 52}, {\"embedding\": 0.8546332716941833, \"dimension\": 4, \"position\": 53}, {\"embedding\": 0.7619734406471252, \"dimension\": 4, \"position\": 54}, {\"embedding\": 0.6502137184143066, \"dimension\": 4, \"position\": 55}, {\"embedding\": 0.5221555233001709, \"dimension\": 4, \"position\": 56}, {\"embedding\": 0.38100889325141907, \"dimension\": 4, \"position\": 57}, {\"embedding\": 0.23031172156333923, \"dimension\": 4, \"position\": 58}, {\"embedding\": 0.07384055852890015, \"dimension\": 4, \"position\": 59}, {\"embedding\": -0.08448058366775513, \"dimension\": 4, \"position\": 60}, {\"embedding\": -0.2406841218471527, \"dimension\": 4, \"position\": 61}, {\"embedding\": -0.3908545970916748, \"dimension\": 4, \"position\": 62}, {\"embedding\": -0.5312277674674988, \"dimension\": 4, \"position\": 63}, {\"embedding\": -0.6582850813865662, \"dimension\": 4, \"position\": 64}, {\"embedding\": -0.768841564655304, \"dimension\": 4, \"position\": 65}, {\"embedding\": -0.8601260781288147, \"dimension\": 4, \"position\": 66}, {\"embedding\": -0.9298503994941711, \"dimension\": 4, \"position\": 67}, {\"embedding\": -0.9762668013572693, \"dimension\": 4, \"position\": 68}, {\"embedding\": -0.9982118010520935, \"dimension\": 4, \"position\": 69}, {\"embedding\": -0.9951352477073669, \"dimension\": 4, \"position\": 70}, {\"embedding\": -0.967114269733429, \"dimension\": 4, \"position\": 71}, {\"embedding\": -0.9148513078689575, \"dimension\": 4, \"position\": 72}, {\"embedding\": -0.839656412601471, \"dimension\": 4, \"position\": 73}, {\"embedding\": -0.7434144616127014, \"dimension\": 4, \"position\": 74}, {\"embedding\": -0.6285378336906433, \"dimension\": 4, \"position\": 75}, {\"embedding\": -0.4979061186313629, \"dimension\": 4, \"position\": 76}, {\"embedding\": -0.3547937273979187, \"dimension\": 4, \"position\": 77}, {\"embedding\": -0.20278796553611755, \"dimension\": 4, \"position\": 78}, {\"embedding\": -0.04569905996322632, \"dimension\": 4, \"position\": 79}, {\"embedding\": 0.11253630369901657, \"dimension\": 4, \"position\": 80}, {\"embedding\": 0.2679498493671417, \"dimension\": 4, \"position\": 81}, {\"embedding\": 0.4166468679904938, \"dimension\": 4, \"position\": 82}, {\"embedding\": 0.5549001097679138, \"dimension\": 4, \"position\": 83}, {\"embedding\": 0.6792440414428711, \"dimension\": 4, \"position\": 84}, {\"embedding\": 0.7865618467330933, \"dimension\": 4, \"position\": 85}, {\"embedding\": 0.8741634488105774, \"dimension\": 4, \"position\": 86}, {\"embedding\": 0.9398530125617981, \"dimension\": 4, \"position\": 87}, {\"embedding\": 0.9819839596748352, \"dimension\": 4, \"position\": 88}, {\"embedding\": 0.9995002150535583, \"dimension\": 4, \"position\": 89}, {\"embedding\": 0.9919626712799072, \"dimension\": 4, \"position\": 90}, {\"embedding\": 0.959559977054596, \"dimension\": 4, \"position\": 91}, {\"embedding\": 0.903104841709137, \"dimension\": 4, \"position\": 92}, {\"embedding\": 0.8240122199058533, \"dimension\": 4, \"position\": 93}, {\"embedding\": 0.7242646217346191, \"dimension\": 4, \"position\": 94}, {\"embedding\": 0.6063624024391174, \"dimension\": 4, \"position\": 95}, {\"embedding\": 0.4732609689235687, \"dimension\": 4, \"position\": 96}, {\"embedding\": 0.32829657196998596, \"dimension\": 4, \"position\": 97}, {\"embedding\": 0.17510302364826202, \"dimension\": 4, \"position\": 98}, {\"embedding\": 0.01752028614282608, \"dimension\": 4, \"position\": 99}, {\"embedding\": 1.0, \"dimension\": 5, \"position\": 0}, {\"embedding\": 0.9874668121337891, \"dimension\": 5, \"position\": 1}, {\"embedding\": 0.9501814842224121, \"dimension\": 5, \"position\": 2}, {\"embedding\": 0.8890786170959473, \"dimension\": 5, \"position\": 3}, {\"embedding\": 0.8056897521018982, \"dimension\": 5, \"position\": 4}, {\"embedding\": 0.7021052241325378, \"dimension\": 5, \"position\": 5}, {\"embedding\": 0.5809215903282166, \"dimension\": 5, \"position\": 6}, {\"embedding\": 0.44517630338668823, \"dimension\": 5, \"position\": 7}, {\"embedding\": 0.2982720732688904, \"dimension\": 5, \"position\": 8}, {\"embedding\": 0.14389123022556305, \"dimension\": 5, \"position\": 9}, {\"embedding\": -0.01409643329679966, \"dimension\": 5, \"position\": 10}, {\"embedding\": -0.1717306226491928, \"dimension\": 5, \"position\": 11}, {\"embedding\": -0.32506027817726135, \"dimension\": 5, \"position\": 12}, {\"embedding\": -0.47024187445640564, \"dimension\": 5, \"position\": 13}, {\"embedding\": -0.6036361455917358, \"dimension\": 5, \"position\": 14}, {\"embedding\": -0.7218996286392212, \"dimension\": 5, \"position\": 15}, {\"embedding\": -0.8220675587654114, \"dimension\": 5, \"position\": 16}, {\"embedding\": -0.9016293287277222, \"dimension\": 5, \"position\": 17}, {\"embedding\": -0.9585906267166138, \"dimension\": 5, \"position\": 18}, {\"embedding\": -0.9915235042572021, \"dimension\": 5, \"position\": 19}, {\"embedding\": -0.9996025562286377, \"dimension\": 5, \"position\": 20}, {\"embedding\": -0.9826252460479736, \"dimension\": 5, \"position\": 21}, {\"embedding\": -0.941017210483551, \"dimension\": 5, \"position\": 22}, {\"embedding\": -0.8758211731910706, \"dimension\": 5, \"position\": 23}, {\"embedding\": -0.788671612739563, \"dimension\": 5, \"position\": 24}, {\"embedding\": -0.6817529797554016, \"dimension\": 5, \"position\": 25}, {\"embedding\": -0.5577451586723328, \"dimension\": 5, \"position\": 26}, {\"embedding\": -0.4197568893432617, \"dimension\": 5, \"position\": 27}, {\"embedding\": -0.27124688029289246, \"dimension\": 5, \"position\": 28}, {\"embedding\": -0.11593768745660782, \"dimension\": 5, \"position\": 29}, {\"embedding\": 0.042278096079826355, \"dimension\": 5, \"position\": 30}, {\"embedding\": 0.19943365454673767, \"dimension\": 5, \"position\": 31}, {\"embedding\": 0.3515901565551758, \"dimension\": 5, \"position\": 32}, {\"embedding\": 0.4949335753917694, \"dimension\": 5, \"position\": 33}, {\"embedding\": 0.6258708238601685, \"dimension\": 5, \"position\": 34}, {\"embedding\": 0.7411201596260071, \"dimension\": 5, \"position\": 35}, {\"embedding\": 0.8377919793128967, \"dimension\": 5, \"position\": 36}, {\"embedding\": 0.9134634733200073, \"dimension\": 5, \"position\": 37}, {\"embedding\": 0.9662377834320068, \"dimension\": 5, \"position\": 38}, {\"embedding\": 0.994792103767395, \"dimension\": 5, \"position\": 39}, {\"embedding\": 0.9984106421470642, \"dimension\": 5, \"position\": 40}, {\"embedding\": 0.9770026803016663, \"dimension\": 5, \"position\": 41}, {\"embedding\": 0.931104838848114, \"dimension\": 5, \"position\": 42}, {\"embedding\": 0.8618676662445068, \"dimension\": 5, \"position\": 43}, {\"embedding\": 0.7710266709327698, \"dimension\": 5, \"position\": 44}, {\"embedding\": 0.6608588695526123, \"dimension\": 5, \"position\": 45}, {\"embedding\": 0.5341253876686096, \"dimension\": 5, \"position\": 46}, {\"embedding\": 0.3940037488937378, \"dimension\": 5, \"position\": 47}, {\"embedding\": 0.24400585889816284, \"dimension\": 5, \"position\": 48}, {\"embedding\": 0.08789165318012238, \"dimension\": 5, \"position\": 49}, {\"embedding\": -0.07042567431926727, \"dimension\": 5, \"position\": 50}, {\"embedding\": -0.2269781529903412, \"dimension\": 5, \"position\": 51}, {\"embedding\": -0.37784066796302795, \"dimension\": 5, \"position\": 52}, {\"embedding\": -0.5192320942878723, \"dimension\": 5, \"position\": 53}, {\"embedding\": -0.6476082801818848, \"dimension\": 5, \"position\": 54}, {\"embedding\": -0.7597513794898987, \"dimension\": 5, \"position\": 55}, {\"embedding\": -0.8528502583503723, \"dimension\": 5, \"position\": 56}, {\"embedding\": -0.9245713949203491, \"dimension\": 5, \"position\": 57}, {\"embedding\": -0.973116934299469, \"dimension\": 5, \"position\": 58}, {\"embedding\": -0.9972700476646423, \"dimension\": 5, \"position\": 59}, {\"embedding\": -0.9964250922203064, \"dimension\": 5, \"position\": 60}, {\"embedding\": -0.9706035256385803, \"dimension\": 5, \"position\": 61}, {\"embedding\": -0.9204524159431458, \"dimension\": 5, \"position\": 62}, {\"embedding\": -0.8472290635108948, \"dimension\": 5, \"position\": 63}, {\"embedding\": -0.7527687549591064, \"dimension\": 5, \"position\": 64}, {\"embedding\": -0.6394393444061279, \"dimension\": 5, \"position\": 65}, {\"embedding\": -0.5100815296173096, \"dimension\": 5, \"position\": 66}, {\"embedding\": -0.3679378628730774, \"dimension\": 5, \"position\": 67}, {\"embedding\": -0.2165713608264923, \"dimension\": 5, \"position\": 68}, {\"embedding\": -0.05977622792124748, \"dimension\": 5, \"position\": 69}, {\"embedding\": 0.09851823002099991, \"dimension\": 5, \"position\": 70}, {\"embedding\": 0.254342257976532, \"dimension\": 5, \"position\": 71}, {\"embedding\": 0.4037908613681793, \"dimension\": 5, \"position\": 72}, {\"embedding\": 0.543117880821228, \"dimension\": 5, \"position\": 73}, {\"embedding\": 0.6688309907913208, \"dimension\": 5, \"position\": 74}, {\"embedding\": 0.7777789831161499, \"dimension\": 5, \"position\": 75}, {\"embedding\": 0.8672309517860413, \"dimension\": 5, \"position\": 76}, {\"embedding\": 0.9349446296691895, \"dimension\": 5, \"position\": 77}, {\"embedding\": 0.9792226552963257, \"dimension\": 5, \"position\": 78}, {\"embedding\": 0.998955249786377, \"dimension\": 5, \"position\": 79}, {\"embedding\": 0.9936476349830627, \"dimension\": 5, \"position\": 80}, {\"embedding\": 0.9634328484535217, \"dimension\": 5, \"position\": 81}, {\"embedding\": 0.9090684056282043, \"dimension\": 5, \"position\": 82}, {\"embedding\": 0.8319169878959656, \"dimension\": 5, \"position\": 83}, {\"embedding\": 0.733912467956543, \"dimension\": 5, \"position\": 84}, {\"embedding\": 0.617511510848999, \"dimension\": 5, \"position\": 85}, {\"embedding\": 0.4856317937374115, \"dimension\": 5, \"position\": 86}, {\"embedding\": 0.3415791094303131, \"dimension\": 5, \"position\": 87}, {\"embedding\": 0.18896427750587463, \"dimension\": 5, \"position\": 88}, {\"embedding\": 0.0316128134727478, \"dimension\": 5, \"position\": 89}, {\"embedding\": -0.12653106451034546, \"dimension\": 5, \"position\": 90}, {\"embedding\": -0.28150418400764465, \"dimension\": 5, \"position\": 91}, {\"embedding\": -0.4294200837612152, \"dimension\": 5, \"position\": 92}, {\"embedding\": -0.5665720105171204, \"dimension\": 5, \"position\": 93}, {\"embedding\": -0.6895220875740051, \"dimension\": 5, \"position\": 94}, {\"embedding\": -0.7951884269714355, \"dimension\": 5, \"position\": 95}, {\"embedding\": -0.880922257900238, \"dimension\": 5, \"position\": 96}, {\"embedding\": -0.9445747137069702, \"dimension\": 5, \"position\": 97}, {\"embedding\": -0.9845501184463501, \"dimension\": 5, \"position\": 98}, {\"embedding\": -0.9998465180397034, \"dimension\": 5, \"position\": 99}, {\"embedding\": 0.0, \"dimension\": 6, \"position\": 0}, {\"embedding\": 0.06305388361215591, \"dimension\": 6, \"position\": 1}, {\"embedding\": 0.12585683166980743, \"dimension\": 6, \"position\": 2}, {\"embedding\": 0.18815888464450836, \"dimension\": 6, \"position\": 3}, {\"embedding\": 0.24971213936805725, \"dimension\": 6, \"position\": 4}, {\"embedding\": 0.31027159094810486, \"dimension\": 6, \"position\": 5}, {\"embedding\": 0.3695962131023407, \"dimension\": 6, \"position\": 6}, {\"embedding\": 0.4274499714374542, \"dimension\": 6, \"position\": 7}, {\"embedding\": 0.4836025834083557, \"dimension\": 6, \"position\": 8}, {\"embedding\": 0.5378305912017822, \"dimension\": 6, \"position\": 9}, {\"embedding\": 0.5899181365966797, \"dimension\": 6, \"position\": 10}, {\"embedding\": 0.6396579146385193, \"dimension\": 6, \"position\": 11}, {\"embedding\": 0.6868520379066467, \"dimension\": 6, \"position\": 12}, {\"embedding\": 0.7313126921653748, \"dimension\": 6, \"position\": 13}, {\"embedding\": 0.7728629112243652, \"dimension\": 6, \"position\": 14}, {\"embedding\": 0.8113372921943665, \"dimension\": 6, \"position\": 15}, {\"embedding\": 0.8465827703475952, \"dimension\": 6, \"position\": 16}, {\"embedding\": 0.8784590363502502, \"dimension\": 6, \"position\": 17}, {\"embedding\": 0.9068393111228943, \"dimension\": 6, \"position\": 18}, {\"embedding\": 0.9316105246543884, \"dimension\": 6, \"position\": 19}, {\"embedding\": 0.9526742100715637, \"dimension\": 6, \"position\": 20}, {\"embedding\": 0.9699464440345764, \"dimension\": 6, \"position\": 21}, {\"embedding\": 0.9833585619926453, \"dimension\": 6, \"position\": 22}, {\"embedding\": 0.9928570985794067, \"dimension\": 6, \"position\": 23}, {\"embedding\": 0.9984043836593628, \"dimension\": 6, \"position\": 24}, {\"embedding\": 0.999978244304657, \"dimension\": 6, \"position\": 25}, {\"embedding\": 0.9975724220275879, \"dimension\": 6, \"position\": 26}, {\"embedding\": 0.9911965131759644, \"dimension\": 6, \"position\": 27}, {\"embedding\": 0.9808759093284607, \"dimension\": 6, \"position\": 28}, {\"embedding\": 0.9666516780853271, \"dimension\": 6, \"position\": 29}, {\"embedding\": 0.9485803842544556, \"dimension\": 6, \"position\": 30}, {\"embedding\": 0.9267339110374451, \"dimension\": 6, \"position\": 31}, {\"embedding\": 0.9011994004249573, \"dimension\": 6, \"position\": 32}, {\"embedding\": 0.8720782399177551, \"dimension\": 6, \"position\": 33}, {\"embedding\": 0.8394865393638611, \"dimension\": 6, \"position\": 34}, {\"embedding\": 0.8035537600517273, \"dimension\": 6, \"position\": 35}, {\"embedding\": 0.7644230127334595, \"dimension\": 6, \"position\": 36}, {\"embedding\": 0.7222501039505005, \"dimension\": 6, \"position\": 37}, {\"embedding\": 0.6772029399871826, \"dimension\": 6, \"position\": 38}, {\"embedding\": 0.6294605135917664, \"dimension\": 6, \"position\": 39}, {\"embedding\": 0.57921302318573, \"dimension\": 6, \"position\": 40}, {\"embedding\": 0.5266605615615845, \"dimension\": 6, \"position\": 41}, {\"embedding\": 0.4720119535923004, \"dimension\": 6, \"position\": 42}, {\"embedding\": 0.41548484563827515, \"dimension\": 6, \"position\": 43}, {\"embedding\": 0.3573042154312134, \"dimension\": 6, \"position\": 44}, {\"embedding\": 0.29770180583000183, \"dimension\": 6, \"position\": 45}, {\"embedding\": 0.23691439628601074, \"dimension\": 6, \"position\": 46}, {\"embedding\": 0.17518411576747894, \"dimension\": 6, \"position\": 47}, {\"embedding\": 0.1127568930387497, \"dimension\": 6, \"position\": 48}, {\"embedding\": 0.04988069087266922, \"dimension\": 6, \"position\": 49}, {\"embedding\": -0.013194027356803417, \"dimension\": 6, \"position\": 50}, {\"embedding\": -0.07621623575687408, \"dimension\": 6, \"position\": 51}, {\"embedding\": -0.1389348804950714, \"dimension\": 6, \"position\": 52}, {\"embedding\": -0.20110084116458893, \"dimension\": 6, \"position\": 53}, {\"embedding\": -0.2624664604663849, \"dimension\": 6, \"position\": 54}, {\"embedding\": -0.3227875530719757, \"dimension\": 6, \"position\": 55}, {\"embedding\": -0.3818237781524658, \"dimension\": 6, \"position\": 56}, {\"embedding\": -0.4393406808376312, \"dimension\": 6, \"position\": 57}, {\"embedding\": -0.49510911107063293, \"dimension\": 6, \"position\": 58}, {\"embedding\": -0.5489069223403931, \"dimension\": 6, \"position\": 59}, {\"embedding\": -0.6005204319953918, \"dimension\": 6, \"position\": 60}, {\"embedding\": -0.6497439742088318, \"dimension\": 6, \"position\": 61}, {\"embedding\": -0.6963817477226257, \"dimension\": 6, \"position\": 62}, {\"embedding\": -0.7402478456497192, \"dimension\": 6, \"position\": 63}, {\"embedding\": -0.7811681628227234, \"dimension\": 6, \"position\": 64}, {\"embedding\": -0.8189795017242432, \"dimension\": 6, \"position\": 65}, {\"embedding\": -0.8535317182540894, \"dimension\": 6, \"position\": 66}, {\"embedding\": -0.8846868872642517, \"dimension\": 6, \"position\": 67}, {\"embedding\": -0.9123212099075317, \"dimension\": 6, \"position\": 68}, {\"embedding\": -0.936324954032898, \"dimension\": 6, \"position\": 69}, {\"embedding\": -0.956602156162262, \"dimension\": 6, \"position\": 70}, {\"embedding\": -0.9730724096298218, \"dimension\": 6, \"position\": 71}, {\"embedding\": -0.9856699705123901, \"dimension\": 6, \"position\": 72}, {\"embedding\": -0.9943448305130005, \"dimension\": 6, \"position\": 73}, {\"embedding\": -0.9990625381469727, \"dimension\": 6, \"position\": 74}, {\"embedding\": -0.9998041391372681, \"dimension\": 6, \"position\": 75}, {\"embedding\": -0.9965668320655823, \"dimension\": 6, \"position\": 76}, {\"embedding\": -0.9893633723258972, \"dimension\": 6, \"position\": 77}, {\"embedding\": -0.9782225489616394, \"dimension\": 6, \"position\": 78}, {\"embedding\": -0.963188648223877, \"dimension\": 6, \"position\": 79}, {\"embedding\": -0.9443213939666748, \"dimension\": 6, \"position\": 80}, {\"embedding\": -0.9216960668563843, \"dimension\": 6, \"position\": 81}, {\"embedding\": -0.8954026699066162, \"dimension\": 6, \"position\": 82}, {\"embedding\": -0.8655455708503723, \"dimension\": 6, \"position\": 83}, {\"embedding\": -0.8322440981864929, \"dimension\": 6, \"position\": 84}, {\"embedding\": -0.795630156993866, \"dimension\": 6, \"position\": 85}, {\"embedding\": -0.7558501362800598, \"dimension\": 6, \"position\": 86}, {\"embedding\": -0.7130619883537292, \"dimension\": 6, \"position\": 87}, {\"embedding\": -0.6674357056617737, \"dimension\": 6, \"position\": 88}, {\"embedding\": -0.6191535592079163, \"dimension\": 6, \"position\": 89}, {\"embedding\": -0.5684073567390442, \"dimension\": 6, \"position\": 90}, {\"embedding\": -0.5153986215591431, \"dimension\": 6, \"position\": 91}, {\"embedding\": -0.46033912897109985, \"dimension\": 6, \"position\": 92}, {\"embedding\": -0.40344759821891785, \"dimension\": 6, \"position\": 93}, {\"embedding\": -0.3449500501155853, \"dimension\": 6, \"position\": 94}, {\"embedding\": -0.28508007526397705, \"dimension\": 6, \"position\": 95}, {\"embedding\": -0.22407560050487518, \"dimension\": 6, \"position\": 96}, {\"embedding\": -0.1621788740158081, \"dimension\": 6, \"position\": 97}, {\"embedding\": -0.09963719546794891, \"dimension\": 6, \"position\": 98}, {\"embedding\": -0.03669850528240204, \"dimension\": 6, \"position\": 99}, {\"embedding\": 1.0, \"dimension\": 7, \"position\": 0}, {\"embedding\": 0.9980100989341736, \"dimension\": 7, \"position\": 1}, {\"embedding\": 0.9920483827590942, \"dimension\": 7, \"position\": 2}, {\"embedding\": 0.9821385741233826, \"dimension\": 7, \"position\": 3}, {\"embedding\": 0.9683201313018799, \"dimension\": 7, \"position\": 4}, {\"embedding\": 0.9506479501724243, \"dimension\": 7, \"position\": 5}, {\"embedding\": 0.9291924834251404, \"dimension\": 7, \"position\": 6}, {\"embedding\": 0.9040390253067017, \"dimension\": 7, \"position\": 7}, {\"embedding\": 0.8752877116203308, \"dimension\": 7, \"position\": 8}, {\"embedding\": 0.8430529236793518, \"dimension\": 7, \"position\": 9}, {\"embedding\": 0.8074630498886108, \"dimension\": 7, \"position\": 10}, {\"embedding\": 0.7686597108840942, \"dimension\": 7, \"position\": 11}, {\"embedding\": 0.7267972826957703, \"dimension\": 7, \"position\": 12}, {\"embedding\": 0.6820423603057861, \"dimension\": 7, \"position\": 13}, {\"embedding\": 0.6345730423927307, \"dimension\": 7, \"position\": 14}, {\"embedding\": 0.5845783352851868, \"dimension\": 7, \"position\": 15}, {\"embedding\": 0.532257080078125, \"dimension\": 7, \"position\": 16}, {\"embedding\": 0.47781768441200256, \"dimension\": 7, \"position\": 17}, {\"embedding\": 0.4214765727519989, \"dimension\": 7, \"position\": 18}, {\"embedding\": 0.36345821619033813, \"dimension\": 7, \"position\": 19}, {\"embedding\": 0.30399325489997864, \"dimension\": 7, \"position\": 20}, {\"embedding\": 0.243318572640419, \"dimension\": 7, \"position\": 21}, {\"embedding\": 0.18167544901371002, \"dimension\": 7, \"position\": 22}, {\"embedding\": 0.11930941045284271, \"dimension\": 7, \"position\": 23}, {\"embedding\": 0.056468550115823746, \"dimension\": 7, \"position\": 24}, {\"embedding\": -0.006597157102078199, \"dimension\": 7, \"position\": 25}, {\"embedding\": -0.06963648647069931, \"dimension\": 7, \"position\": 26}, {\"embedding\": -0.1323987990617752, \"dimension\": 7, \"position\": 27}, {\"embedding\": -0.1946340948343277, \"dimension\": 7, \"position\": 28}, {\"embedding\": -0.25609490275382996, \"dimension\": 7, \"position\": 29}, {\"embedding\": -0.31653639674186707, \"dimension\": 7, \"position\": 30}, {\"embedding\": -0.37571826577186584, \"dimension\": 7, \"position\": 31}, {\"embedding\": -0.43340474367141724, \"dimension\": 7, \"position\": 32}, {\"embedding\": -0.4893665015697479, \"dimension\": 7, \"position\": 33}, {\"embedding\": -0.5433804988861084, \"dimension\": 7, \"position\": 34}, {\"embedding\": -0.5952321887016296, \"dimension\": 7, \"position\": 35}, {\"embedding\": -0.6447150111198425, \"dimension\": 7, \"position\": 36}, {\"embedding\": -0.6916319727897644, \"dimension\": 7, \"position\": 37}, {\"embedding\": -0.7357962727546692, \"dimension\": 7, \"position\": 38}, {\"embedding\": -0.7770324349403381, \"dimension\": 7, \"position\": 39}, {\"embedding\": -0.8151761889457703, \"dimension\": 7, \"position\": 40}, {\"embedding\": -0.8500756621360779, \"dimension\": 7, \"position\": 41}, {\"embedding\": -0.8815921545028687, \"dimension\": 7, \"position\": 42}, {\"embedding\": -0.9096000790596008, \"dimension\": 7, \"position\": 43}, {\"embedding\": -0.933988094329834, \"dimension\": 7, \"position\": 44}, {\"embedding\": -0.9546589255332947, \"dimension\": 7, \"position\": 45}, {\"embedding\": -0.971530556678772, \"dimension\": 7, \"position\": 46}, {\"embedding\": -0.9845356941223145, \"dimension\": 7, \"position\": 47}, {\"embedding\": -0.9936226010322571, \"dimension\": 7, \"position\": 48}, {\"embedding\": -0.998755156993866, \"dimension\": 7, \"position\": 49}, {\"embedding\": -0.9999129772186279, \"dimension\": 7, \"position\": 50}, {\"embedding\": -0.9970912933349609, \"dimension\": 7, \"position\": 51}, {\"embedding\": -0.9903014898300171, \"dimension\": 7, \"position\": 52}, {\"embedding\": -0.9795705676078796, \"dimension\": 7, \"position\": 53}, {\"embedding\": -0.964941143989563, \"dimension\": 7, \"position\": 54}, {\"embedding\": -0.9464714527130127, \"dimension\": 7, \"position\": 55}, {\"embedding\": -0.9242351651191711, \"dimension\": 7, \"position\": 56}, {\"embedding\": -0.8983205556869507, \"dimension\": 7, \"position\": 57}, {\"embedding\": -0.8688308000564575, \"dimension\": 7, \"position\": 58}, {\"embedding\": -0.8358834981918335, \"dimension\": 7, \"position\": 59}, {\"embedding\": -0.7996094226837158, \"dimension\": 7, \"position\": 60}, {\"embedding\": -0.7601531147956848, \"dimension\": 7, \"position\": 61}, {\"embedding\": -0.7176715731620789, \"dimension\": 7, \"position\": 62}, {\"embedding\": -0.6723340749740601, \"dimension\": 7, \"position\": 63}, {\"embedding\": -0.6243206262588501, \"dimension\": 7, \"position\": 64}, {\"embedding\": -0.5738227963447571, \"dimension\": 7, \"position\": 65}, {\"embedding\": -0.5210408568382263, \"dimension\": 7, \"position\": 66}, {\"embedding\": -0.46618568897247314, \"dimension\": 7, \"position\": 67}, {\"embedding\": -0.4094752371311188, \"dimension\": 7, \"position\": 68}, {\"embedding\": -0.3511347472667694, \"dimension\": 7, \"position\": 69}, {\"embedding\": -0.2913972735404968, \"dimension\": 7, \"position\": 70}, {\"embedding\": -0.23049965500831604, \"dimension\": 7, \"position\": 71}, {\"embedding\": -0.1686851680278778, \"dimension\": 7, \"position\": 72}, {\"embedding\": -0.10619935393333435, \"dimension\": 7, \"position\": 73}, {\"embedding\": -0.04329042136669159, \"dimension\": 7, \"position\": 74}, {\"embedding\": 0.019790323451161385, \"dimension\": 7, \"position\": 75}, {\"embedding\": 0.08279230445623398, \"dimension\": 7, \"position\": 76}, {\"embedding\": 0.14546526968479156, \"dimension\": 7, \"position\": 77}, {\"embedding\": 0.20755885541439056, \"dimension\": 7, \"position\": 78}, {\"embedding\": 0.2688263952732086, \"dimension\": 7, \"position\": 79}, {\"embedding\": 0.3290245532989502, \"dimension\": 7, \"position\": 80}, {\"embedding\": 0.3879128098487854, \"dimension\": 7, \"position\": 81}, {\"embedding\": 0.4452572762966156, \"dimension\": 7, \"position\": 82}, {\"embedding\": 0.5008301138877869, \"dimension\": 7, \"position\": 83}, {\"embedding\": 0.5544094443321228, \"dimension\": 7, \"position\": 84}, {\"embedding\": 0.605782687664032, \"dimension\": 7, \"position\": 85}, {\"embedding\": 0.6547446846961975, \"dimension\": 7, \"position\": 86}, {\"embedding\": 0.7011010050773621, \"dimension\": 7, \"position\": 87}, {\"embedding\": 0.7446674108505249, \"dimension\": 7, \"position\": 88}, {\"embedding\": 0.7852699160575867, \"dimension\": 7, \"position\": 89}, {\"embedding\": 0.8227472901344299, \"dimension\": 7, \"position\": 90}, {\"embedding\": 0.856950581073761, \"dimension\": 7, \"position\": 91}, {\"embedding\": 0.8877431154251099, \"dimension\": 7, \"position\": 92}, {\"embedding\": 0.9150027632713318, \"dimension\": 7, \"position\": 93}, {\"embedding\": 0.9386210441589355, \"dimension\": 7, \"position\": 94}, {\"embedding\": 0.9585037231445312, \"dimension\": 7, \"position\": 95}, {\"embedding\": 0.9745717644691467, \"dimension\": 7, \"position\": 96}, {\"embedding\": 0.9867613911628723, \"dimension\": 7, \"position\": 97}, {\"embedding\": 0.9950238466262817, \"dimension\": 7, \"position\": 98}, {\"embedding\": 0.9993264079093933, \"dimension\": 7, \"position\": 99}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "The Positional Encoding output is shown in the Figure below:\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/caglarmert/DI725/blob/main/src/positional_encoding_sine.png?raw=true\" width=\"750\"/>\n",
        "</div>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "AfQ-LiUQ6PL6"
      },
      "id": "AfQ-LiUQ6PL6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.3: Implementing multi-headed self-attention\n",
        "\n",
        "The multi-headed attention mechanisms are highlighted in the Figure below:\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/caglarmert/DI725/blob/main/src/multi_headed_attention_highlighted.png?raw=true\" width=\"400\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The multi-head attention is a form of scaled dot-product attention, calculated as:\n",
        "<div>\n",
        "<img src=\"https://github.com/caglarmert/DI725/blob/main/src/scaled_dot_product_attention_formula.PNG?raw=true\" width=\"400\"/>\n",
        "</div>\n",
        "\n",
        "Scaled dot-product attention demonstrated as:\n",
        "<div>\n",
        "<img src=\"https://github.com/caglarmert/DI725/blob/main/src/scaled_dot_product_attention.PNG?raw=true\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "Multi-head attention calculated as:\n",
        "<div>\n",
        "<img src=\"https://github.com/caglarmert/DI725/blob/main/src/multi_head_Attention_formula.PNG?raw=true\" width=\"600\"/>\n",
        "</div>\n",
        "\n",
        "Multi-head attention demonstrated as:\n",
        "<div>\n",
        "<img src=\"https://github.com/caglarmert/DI725/blob/main/src/multi_head_Attention.PNG?raw=true\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "Building the multi-headed self-attention can be observed from the implementation provided below.\n",
        "\n",
        "#### Instructions\n",
        "* Split the sequence embeddings x across the multiple attention heads.\n",
        "* Compute dot-product based attention scores between the project query and key.\n",
        "* Normalize the attention scores to obtain attention weights.\n",
        "* Multiply the attention weights by the values and linearly transform the concatenated outputs per head."
      ],
      "metadata": {
        "id": "6FZGjkpZ2zHu"
      },
      "id": "6FZGjkpZ2zHu"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b1fb67b6-5884-40ae-9b54-78192b5506d4",
      "metadata": {
        "id": "b1fb67b6-5884-40ae-9b54-78192b5506d4"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        self.head_dim = d_model // num_heads\n",
        "\n",
        "        self.query_linear = nn.Linear(d_model, d_model)\n",
        "        self.key_linear = nn.Linear(d_model, d_model)\n",
        "        self.value_linear = nn.Linear(d_model, d_model)\n",
        "        self.output_linear = nn.Linear(d_model, d_model)\n",
        "    def split_heads(self, x, batch_size):\n",
        "        # Split the sequence embeddings in x across the attention heads\n",
        "        x = x.view(batch_size, -1, self.num_heads, self.head_dim)\n",
        "        return x.permute(0, 2, 1, 3).contiguous().view(batch_size * self.num_heads, -1, self.head_dim)\n",
        "\n",
        "    def compute_attention(self, query, key, mask=None):\n",
        "        # Compute dot-product attention scores\n",
        "        scores = torch.matmul(query, key.permute(1, 2, 0))\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "        # Normalize attention scores into attention weights\n",
        "        attention_weights = F.softmax(scores, dim=-1)\n",
        "        return attention_weights\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        query = self.split_heads(self.query_linear(query), batch_size)\n",
        "        key = self.split_heads(self.key_linear(key), batch_size)\n",
        "        value = self.split_heads(self.value_linear(value), batch_size)\n",
        "\n",
        "        attention_weights = self.compute_attention(query, key, mask)\n",
        "        # print(attention_weights)\n",
        "        # Multiply attention weights by values and linearly project concatenated outputs\n",
        "        output = torch.matmul(attention_weights, value)\n",
        "        output = output.view(batch_size, self.num_heads, -1, self.head_dim).permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.d_model)\n",
        "        return self.output_linear(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.4: Post-attention feed-forward layer\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/caglarmert/DI725/blob/main/src/feed_forward_highlighted.png?raw=true\" width=\"400\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "Feed-forward sublayer following multi-head self-attention for every encoder layer is built as an example below:\n",
        "\n",
        "\n",
        "\n",
        "#### Instructions\n",
        "* Specify in the __init__() method the sizes of the two linear fully connected layers.\n",
        "* Apply a forward pass through the two linear layers, using the ReLU() activation in between."
      ],
      "metadata": {
        "id": "v0ix1uQi3Gkt"
      },
      "id": "v0ix1uQi3Gkt"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f32a3f9f-f65c-450c-b49d-d849b0cdf617",
      "metadata": {
        "id": "f32a3f9f-f65c-450c-b49d-d849b0cdf617"
      },
      "outputs": [],
      "source": [
        "class FeedForwardSubLayer(nn.Module):\n",
        "    # Specify the two linear layers' input and output sizes\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(FeedForwardSubLayer, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    # Apply a forward pass\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder Transformer\n",
        "\n",
        "Useful for tasks like classification, one of the most common application is  BERT (Bidirectional Encoder Representations from Transformers). Applies self-attention to the inputs to determine which parts are more useful for the task.\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/caglarmert/DI725/blob/main/src/Encoder_only_transformer.png?raw=true\" width=\"400\"/>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "xl3xBFBBA3LN"
      },
      "id": "xl3xBFBBA3LN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.5: Encoder layer\n",
        "\n",
        "\n",
        "Assembling a full encoder layer containing:\n",
        "\n",
        "* A multi-headed self-attention mechanism.\n",
        "* A feed-forward sublayer.\n",
        "* A combined layer normalization and dropout to be applied after each of the above two stages.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/caglarmert/DI725/blob/main/src/Encoder_only_transformer_norm_highlighted.png?raw=true\" width=\"300\"/>\n",
        "</div>"
      ],
      "metadata": {
        "id": "uFbiS9Jg4Ic9"
      },
      "id": "uFbiS9Jg4Ic9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the initialization of elements in the encoder layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        # Multi-head self-attention\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        # Feedforward neural network\n",
        "        self.feed_forward = FeedForwardSubLayer(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "      # Multi-head self-attention\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        # Feedforward neural network\n",
        "        ff_output = self.feed_forward(x)\n",
        "        return self.norm2(x + self.dropout(ff_output))"
      ],
      "metadata": {
        "id": "XtH2xwFO4OW3"
      },
      "id": "XtH2xwFO4OW3",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.6: Encoder transformer body and head\n",
        "\n",
        "Implementing the transformer body, that is consisting of a stack of multiple encoder layers and a task specific transformer head that is used to process the encoder's hidden states.\n",
        "\n",
        "Apart from the highlighted components, we have implemented everything so far. The linear layer followed by a softmax to output probabilities is the final implementation we will do in this section.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/caglarmert/DI725/blob/main/src/Encoder_only_transformer_head_highlighted.png?raw=true\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "#### Instructions\n",
        "* Define a stack of multiple encoder layers in the __init__() method.\n",
        "* Complete the forward() method. Note that the process starts by converting the original sequence tokens in x into embeddings.\n",
        "* Add final linear layer to project encoder results into raw classification outputs.\n",
        "* Apply the necessary function to map raw classification outputs into log class probabilities."
      ],
      "metadata": {
        "id": "_8vDWOqJ4Yfb"
      },
      "id": "_8vDWOqJ4Yfb"
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_sequence_length):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model = d_model, max_len = max_sequence_length)\n",
        "        # Define a stack of multiple encoder layers\n",
        "        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "\n",
        "    # Complete the forward pass method\n",
        "    def forward(self, x, mask):\n",
        "        x = self.embedding(x)\n",
        "        x = self.positional_encoding(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return x\n",
        "\n",
        "class ClassifierHead(nn.Module):\n",
        "    def __init__(self, d_model, num_classes):\n",
        "        super(ClassifierHead, self).__init__()\n",
        "        # Add linear layer for multiple-class classification\n",
        "        self.fc = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.fc(x[:, 0, :])\n",
        "        # Obtain log class probabilities upon raw outputs\n",
        "        return F.log_softmax(logits, dim=-1)"
      ],
      "metadata": {
        "id": "c7tjYzQG4PBN"
      },
      "id": "c7tjYzQG4PBN",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.7: Testing the encoder transformer\n",
        "\n",
        "A random and simple sequence will be used as an input to the encoder transformer. Obtaining the output (that is not even human-readable) without any errors is sufficient for this exercise.\n",
        "\n",
        "The following components are adequate to form a full encoder transformer:\n",
        "* PositionalEncoder\n",
        "* MultiHeadAttention\n",
        "* FeedForwardSublayer\n",
        "* EncoderLayer\n",
        "* TransformerEncoder\n",
        "* ClassifierHead\n",
        "\n",
        "Note: although a random input sequence and mask are being used here, in practice, the mask should correspond to the actual location of padding tokens in the input sequences to ensure all of them are the same length.\n",
        "\n",
        "#### Instructions\n",
        "* Instantiate the body and head of the encoder transformer.\n",
        "* Complete the forward pass throughout the entire transformer body and head to obtain and print classification outputs."
      ],
      "metadata": {
        "id": "mdusUqHn4vrs"
      },
      "id": "mdusUqHn4vrs"
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 3\n",
        "vocab_size = 10000\n",
        "batch_size = 8\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "num_layers = 6\n",
        "d_ff = 2048\n",
        "sequence_length = 64\n",
        "dropout = 0.1\n",
        "\n",
        "input_sequence = torch.randint(0, vocab_size, (batch_size, sequence_length))\n",
        "mask = torch.randint(0, 2, (sequence_length, sequence_length))\n",
        "\n",
        "# Instantiate the encoder transformer's body and head\n",
        "encoder = TransformerEncoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_sequence_length=sequence_length)\n",
        "classifier = ClassifierHead(d_model, num_classes)\n",
        "\n",
        "# Complete the forward pass\n",
        "output = encoder(input_sequence, mask)\n",
        "classification = classifier(output)\n",
        "print(\"Classification outputs for a batch of \", batch_size, \"sequences:\")\n",
        "print(classification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGvWfAbYr5Mv",
        "outputId": "b6ec5b92-c1d0-495f-a745-6633d16f9189"
      },
      "id": "vGvWfAbYr5Mv",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification outputs for a batch of  8 sequences:\n",
            "tensor([[-1.7919, -0.7355, -1.0382],\n",
            "        [-1.4779, -1.5639, -0.5753],\n",
            "        [-1.5204, -0.5624, -1.5533],\n",
            "        [-1.7478, -0.3626, -2.0406],\n",
            "        [-1.3476, -0.4823, -2.0975],\n",
            "        [-0.6271, -1.2130, -1.7806],\n",
            "        [-1.2529, -1.2968, -0.8189],\n",
            "        [-1.5385, -0.8650, -1.0099]], grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: although a random input sequence and mask are being used here, in practice, the mask should correspond to the actual location of padding tokens in the input sequences to ensure all of them are the same length."
      ],
      "metadata": {
        "id": "2XYFLPGATsRN"
      },
      "id": "2XYFLPGATsRN"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "iC7VVr3PS4zm",
        "outputId": "ad5ffa82-89db-4a3e-fb97-afdbde930666"
      },
      "id": "iC7VVr3PS4zm",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e453f445570>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder Transformer\n",
        "Used for tasks like text generation, where the model generates text for a given input or prompt. Text generation occurs as a word at a time and conditions on itself (previously generated content) to generate new ones. GPT-3 (Generative Pre-trained Transformer 3) is a well known Decoder Transformer.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/caglarmert/DI725/blob/main/src/decoder_only_transformer.png?raw=true\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g_yPohnTA6i4"
      },
      "id": "g_yPohnTA6i4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.8: Decoder Layer\n",
        "\n",
        "Encoder layer is built similarly, what is the main difference between these two structures?\n",
        "\n",
        "\n",
        "#### Instructions\n",
        "* A multi-headed self-attention mechanism.\n",
        "* A feed-forward sublayer.\n",
        "* Normalization and dropout to be applied."
      ],
      "metadata": {
        "id": "PgiCPIppxepa"
      },
      "id": "PgiCPIppxepa"
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        # Multi-head self-attention\n",
        "        self.self_attention = MultiHeadAttention(d_model, num_heads)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        # Feedforward neural network\n",
        "        self.feed_forward = FeedForwardSubLayer(d_model, d_ff)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, self_mask):\n",
        "        # Multi-head self-attention\n",
        "        attention_output = self.self_attention(x, x, x, self_mask)\n",
        "        x = x + self.dropout(attention_output)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # Feedforward neural network\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = x + self.dropout(ff_output)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "SHslCMRKxe18"
      },
      "id": "SHslCMRKxe18",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.9: Building a decoder body and head\n",
        "\n",
        "A high-level structure for a decoder only transformer will be implemented in this exercise. Different than the encoder transformer, the model body and head is not seperated in decoder transformer. Instead decoder transformer contains the model head and body. The model body is a stack of decoder layers.\n",
        "\n",
        "#### Instructions\n",
        "* Add the linear layer for the model head inside the TransformerDecoder class.\n",
        "* Apply the last stage of the forward pass, through the model head."
      ],
      "metadata": {
        "id": "mXXBXK9t5yFa"
      },
      "id": "mXXBXK9t5yFa"
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoderOnly(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_sequence_length):\n",
        "        super(TransformerDecoderOnly, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model = d_model, max_len = max_sequence_length)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "\n",
        "        # Add a linear layer (head) for next-word prediction\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x, self_mask):\n",
        "        x = self.embedding(x)\n",
        "        x = self.positional_encoding(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, self_mask)\n",
        "\n",
        "        # Apply the forward pass through the model head\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "metadata": {
        "id": "DGiGIeNm4PG3"
      },
      "id": "DGiGIeNm4PG3",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.10: Testing the decoder transformer\n",
        "\n",
        "A random and simple sequence will be used as an input to the decoder transformer. Obtaining the output without any errors is sufficient for this exercise.\n",
        "\n",
        "The following components are adequate to form a full decoder transformer:\n",
        "* PositionalEncoder\n",
        "* MultiHeadAttention\n",
        "* FeedForwardSublayer\n",
        "* DecoderLayer\n",
        "* TransformerDecoder\n",
        "\n",
        "#### Instructions\n",
        "* Implement the decoder transformer with methods and classes defined before.\n",
        "* Complete the forward pass throughout the entire transformer body and head to obtain and print  outputs."
      ],
      "metadata": {
        "id": "ahPqhTJ06BIP"
      },
      "id": "ahPqhTJ06BIP"
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 3\n",
        "vocab_size = 10000\n",
        "batch_size = 8\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "num_layers = 6\n",
        "d_ff = 2048\n",
        "sequence_length = 64\n",
        "dropout = 0.1\n",
        "\n",
        "input_sequence = torch.randint(0, vocab_size, (batch_size, sequence_length))\n",
        "\n",
        "# Create a triangular attention mask for causal attention\n",
        "self_attention_mask = (1 - torch.triu(torch.ones(1, sequence_length, sequence_length), diagonal=1)).bool()\n",
        "\n",
        "# Instantiate the decoder transformer\n",
        "decoder = TransformerDecoderOnly(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_sequence_length=sequence_length)\n",
        "\n",
        "output = decoder(input_sequence, self_attention_mask)\n",
        "print(output.shape)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFMAatSbvg5e",
        "outputId": "13f39b3c-cbe0-432d-a600-e2bc5364258a"
      },
      "id": "HFMAatSbvg5e",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 64, 10000])\n",
            "tensor([[[ -9.5791,  -8.6842,  -8.6121,  ...,  -9.6699,  -9.9733,  -8.6570],\n",
            "         [ -9.9541,  -8.2981,  -9.4959,  ...,  -9.0097,  -9.5979,  -8.7411],\n",
            "         [ -9.8757,  -9.4634,  -9.7816,  ...,  -9.8617,  -9.5334,  -8.6165],\n",
            "         ...,\n",
            "         [ -8.9796,  -9.5739,  -9.3245,  ...,  -9.7411,  -9.7388,  -8.1919],\n",
            "         [ -9.1190,  -9.2781, -10.1668,  ...,  -9.8819,  -9.1584,  -9.2495],\n",
            "         [ -9.4095,  -8.9786, -10.1873,  ..., -10.6112,  -9.8275,  -8.3834]],\n",
            "\n",
            "        [[-10.1584,  -9.1244,  -9.1096,  ...,  -9.6161,  -9.7900,  -9.1598],\n",
            "         [ -9.8503,  -9.6460,  -9.3513,  ..., -10.1542,  -9.4933,  -9.1431],\n",
            "         [-10.6940,  -8.3794,  -9.8954,  ...,  -9.1660,  -9.7738,  -8.6646],\n",
            "         ...,\n",
            "         [ -9.9759,  -9.3844,  -9.5905,  ...,  -9.3136,  -8.2080,  -9.2692],\n",
            "         [ -8.8906,  -8.8757,  -9.9566,  ...,  -9.6446,  -7.7015,  -9.2111],\n",
            "         [ -9.3049,  -8.9720,  -9.7557,  ...,  -9.3667,  -8.9033,  -9.0596]],\n",
            "\n",
            "        [[ -9.6093,  -8.3423,  -9.4718,  ...,  -9.3554,  -9.1039, -10.4282],\n",
            "         [-10.2546,  -8.1568,  -9.9601,  ...,  -9.8249,  -8.4826,  -8.9840],\n",
            "         [-11.0923,  -9.3159,  -9.1485,  ...,  -9.8231,  -9.1966,  -9.0046],\n",
            "         ...,\n",
            "         [-10.1114,  -9.3969,  -9.5081,  ..., -10.1324,  -9.8964,  -9.4616],\n",
            "         [ -8.8892,  -9.9708,  -9.4429,  ...,  -9.2063,  -9.7957,  -8.9746],\n",
            "         [ -9.6352,  -9.3112, -10.1159,  ...,  -9.4093,  -9.0564,  -8.7059]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-10.0075,  -9.1053,  -8.4095,  ...,  -9.7772,  -9.8258,  -9.6994],\n",
            "         [ -9.8931,  -8.7821,  -9.5015,  ...,  -9.3877,  -9.2344,  -9.3413],\n",
            "         [ -9.3253,  -8.9519,  -9.3584,  ..., -10.4335,  -8.9731,  -9.6663],\n",
            "         ...,\n",
            "         [ -9.8403,  -9.1714,  -9.5600,  ..., -10.6431,  -9.1566,  -8.0602],\n",
            "         [ -8.5344,  -9.3442,  -9.1377,  ...,  -9.6357,  -9.6075,  -9.1902],\n",
            "         [ -8.3023,  -9.7701, -10.2460,  ...,  -8.8650,  -9.4337, -10.2030]],\n",
            "\n",
            "        [[ -9.3775,  -8.6980,  -8.6875,  ...,  -9.6912,  -9.7932,  -8.9840],\n",
            "         [ -9.4218,  -9.6354,  -9.7683,  ...,  -9.7792,  -9.4228,  -9.0308],\n",
            "         [ -9.3133,  -9.5659,  -9.8766,  ...,  -8.7207,  -9.9813, -10.0605],\n",
            "         ...,\n",
            "         [ -9.9914,  -8.7509,  -9.7106,  ...,  -9.6811,  -9.4454,  -9.1822],\n",
            "         [ -9.7363,  -8.3941, -10.9407,  ...,  -9.9107,  -9.6236,  -9.2680],\n",
            "         [-10.1271,  -9.9420, -10.0287,  ...,  -9.1978,  -8.4534,  -9.6781]],\n",
            "\n",
            "        [[-10.2851,  -9.0432,  -9.4266,  ..., -10.3303, -10.1910,  -9.5703],\n",
            "         [-10.5757,  -7.7636,  -8.9803,  ..., -10.2457,  -9.7368,  -9.1001],\n",
            "         [-10.0142,  -8.3213,  -8.9338,  ...,  -9.9428,  -9.5109, -10.0604],\n",
            "         ...,\n",
            "         [ -8.9214,  -9.2971,  -9.7950,  ...,  -9.7088,  -9.6762,  -9.1208],\n",
            "         [ -9.1716,  -9.3411,  -9.7168,  ..., -10.0293,  -9.4379,  -8.6355],\n",
            "         [ -9.3661, -10.2972,  -9.6628,  ..., -10.2744,  -9.3873,  -9.6602]]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The triangular mask defined here is the causal mask that prohibits the decoder from observing the \"future\" or cheating. For the first element in the sequence, the decoder can only observe the first element, for the second: the second and the first... for nth element, the decoder can only observe elements (tokens) up to the nth element, basically the last generated element and all previous ones."
      ],
      "metadata": {
        "id": "4_p3PvxyTyyN"
      },
      "id": "4_p3PvxyTyyN"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(self_attention_mask[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "8IqI7WqJT77t",
        "outputId": "cf925882-1b56-4066-ed19-3f9005a3188c"
      },
      "id": "8IqI7WqJT77t",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e453f1eb1c0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder-Decoder Transformer\n",
        "Useful for translation tasks, where a given input text is required to be translated into an output in a target language. T5 (Text-to-Text Transfer Transformer) is a well known encoder-decoder transformer which can also do summarization, question answering as well as translation."
      ],
      "metadata": {
        "id": "Z-M0a32yA8yR"
      },
      "id": "Z-M0a32yA8yR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.11: Incorporating cross-attention in a decoder\n",
        "\n",
        "In an encoder-decoder transformer, decoder layers incorporate two attention mechanisms: the causal attention inherent to any transformer decoder, plus a cross-attention that integrates source sequence information processed by the encoder with the target sequence information being processed through the decoder.\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/caglarmert/DI725/blob/main/src/Cross_attention.png?raw=true\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "Modify the DecoderLayer class to incorporate this twofold attention scheme.\n",
        "\n",
        "#### Instructions\n",
        "* Initialize the two attention mechanisms used in an encoder-decoder transformers' decoder layer: causal (masked) self-attention and cross-attention.\n",
        "* Pass the necessary input arguments (query, key, values, and mask) to the two attention stages in the forward pass."
      ],
      "metadata": {
        "id": "ZBaL5H4lKLlY"
      },
      "id": "ZBaL5H4lKLlY"
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        # Initialize the causal (masked) self-attention and cross-attention\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = FeedForwardSubLayer(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, causal_mask, encoder_output, cross_mask):\n",
        "        # Pass the necessary arguments to the causal self-attention and cross-attention\n",
        "        self_attn_output = self.self_attn(x, x, x, causal_mask)\n",
        "        x = self.norm1(x + self.dropout(self_attn_output))\n",
        "        cross_attn_output = self.cross_attn(x, encoder_output, encoder_output, cross_mask)\n",
        "        # (query, key, values, and mask)\n",
        "        x = self.norm2(x + self.dropout(cross_attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x"
      ],
      "metadata": {
        "id": "7drUCHLr6Kb5"
      },
      "id": "7drUCHLr6Kb5",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.12: Updating Decoder Transformer"
      ],
      "metadata": {
        "id": "l_m2lLe35zyd"
      },
      "id": "l_m2lLe35zyd"
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_sequence_length):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model = d_model, max_len = max_sequence_length)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, causal_mask, encoder_output, cross_mask):\n",
        "        x = self.embedding(x)\n",
        "        x = self.positional_encoding(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, causal_mask, encoder_output, cross_mask)\n",
        "        return x"
      ],
      "metadata": {
        "id": "xJgCmGfv5t1h"
      },
      "id": "xJgCmGfv5t1h",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.13: Trying out an encoder-decoder transformer\n",
        "Your next task is complete the following piece of code to define and forward-pass an example batch of randomly generated input sequences through an encoder-decoder transformer.\n",
        "\n",
        "Remember that we are only testing a yet-to-be-trained transformer architecture, hence the use of random input sequences.\n",
        "\n",
        "The following components are required to form a full encoder-decoder transformer:\n",
        "* MultiHeadAttention\n",
        "* FeedForwardSubLayer\n",
        "* PositionalEncoding\n",
        "* EncoderLayer\n",
        "* DecoderLayer\n",
        "* TransformerEncoder\n",
        "* TransformerDecoder\n",
        "* ClassifierHead\n",
        "\n",
        "\n",
        "#### Instructions\n",
        "\n",
        "* Create a batch of random input sequences of size batch_size X sequence_length.\n",
        "* Instantiate the two transformer bodies using the appropriate class names.\n",
        "* Pass the necessary masks as arguments to the encoder and the decoder for their underlying attention mechanisms; each mask argument should be added in the same order they are utilized inside the encoder or decoder layer."
      ],
      "metadata": {
        "id": "XEr8387SKV65"
      },
      "id": "XEr8387SKV65"
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "batch_size = 16\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "num_layers = 6\n",
        "d_ff = 2048\n",
        "sequence_length = 128\n",
        "dropout = 0.1\n",
        "\n",
        "\n",
        "# Create a batch of random input sequences\n",
        "input_sequence = torch.randint(0, vocab_size, (batch_size, sequence_length))\n",
        "padding_mask = torch.randint(0, 2, (sequence_length, sequence_length))\n",
        "causal_mask = torch.triu(torch.ones(sequence_length, sequence_length), diagonal=1)\n",
        "\n",
        "# Instantiate the two transformer bodies\n",
        "encoder = TransformerEncoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_sequence_length=sequence_length)\n",
        "decoder = TransformerDecoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_sequence_length=sequence_length)\n",
        "\n",
        "# Pass the necessary masks as arguments to the encoder and the decoder\n",
        "encoder_output = encoder(input_sequence, padding_mask)\n",
        "decoder_output = decoder(input_sequence, causal_mask, encoder_output, padding_mask)\n",
        "print(\"Batch's output shape: \", decoder_output.shape)"
      ],
      "metadata": {
        "id": "PF-GaVkHKAQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53e36e1-481d-4211-d6df-049e7b968599"
      },
      "id": "PF-GaVkHKAQK",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch's output shape:  torch.Size([16, 128, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the causal mask for the Encoder-Decoder Transformer"
      ],
      "metadata": {
        "id": "gK_WUwsNU2ZH"
      },
      "id": "gK_WUwsNU2ZH"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(causal_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "ypAizhx3U2hF",
        "outputId": "7352fb35-1c99-4ce3-c90b-cd95b68219e6"
      },
      "id": "ypAizhx3U2hF",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e453a5172b0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGhCAYAAADbf0s2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCGElEQVR4nO3deXyU5b3//9csyWSfLJANCARFFkGQPerxWM0pLkdRsR499IjVR21PcaHYVrBVv5wqWOvSalupnlbbX7VaW6mKiFJAFmWPrEoEQVYnIZNkJguZzNxz/f7ot/kai8oyyT0zeT8fj3k8zD333PlcGPLm+sw11+0wxhhERETikNPuAkRERD6PQkpEROKWQkpEROKWQkpEROKWQkpEROKWQkpEROKWQkpEROKWQkpEROKWQkpEROKWQkpEROKWbSH1y1/+kgEDBpCWlsaECRNYv369XaWIiEicsiWkXnzxRWbOnMl9991HVVUVI0eOZNKkSdTW1tpRjoiIxCmHHRvMTpgwgXHjxvGLX/wCgGg0Sr9+/bjtttuYNWvWl74+Go1y+PBhsrOzcTgcXV2uiIjEmDGGpqYmSktLcTo/f77k7saaAGhvb2fTpk3Mnj2745jT6aSyspI1a9Yc8zWhUIhQKNTx9aFDhxg2bFiX1yoiIl3rwIED9O3b93Of7/aQqqurw7IsioqKOh0vKipi586dx3zNvHnzmDNnzj8dP49LMV8Zx/7/gNP71jA+fx//lbuJPu6sLqldRERiI9gcpf/oj8nOzv7C87o9pE7G7NmzmTlzZsfXwWCQfv364SYFz3YfQ5pLiGSV8dLFg5g45RBDM1ttrFZERI7Xl71l0+0h1atXL1wuFzU1NZ2O19TUUFxcfMzXeDwePB7PMZ+z6vxQ58fldJE1bAK+SC5h04QTBy6HVtiLiCSybv8tnpqaypgxY1i6dGnHsWg0ytKlS6moqDj5C5so3o/DzFt1GROrrufu2tHUWi0xqFhEROxiS7tv5syZTJs2jbFjxzJ+/Hh+9rOf0dLSwje+8Y2Tv6gxZKzZzdCPe2NlefjzdRO54soqCl2xq1tERLqXLSH1H//xHxw5coR7770Xn8/HqFGjWLx48T8tpjhRVkMDNDTg8HhIv3AMvkguzdFaUhwuPI6UGFUvIiLdxZbPSZ2qYDCI1+vlAibjPkb4ONxuWi8bzcGvOnDnt3HpGTu4r3Alea4MG6oVEZHPCjZFyTtjD4FAgJycnM89LylXFphIhKwV1Qx92MfAhyK8unYMPsvuqkRE5EQlxBL0k2E1BqAxgCvXS6p/GHsi+eQ668h2uslyptldnoiIHIekDal/MG0hCqss7si8ESsvwuSRm7m/aLWCSkQkASRlu+/Tom1tZC7ZwRkP7WHIz1t4ZcsomqIRu8sSEZHjkPQzKYBoSwu0tOACXPVeqtp7MSDaQKnLaDGFiEgc6xEh9Q+muYXS1VHubP0G7QVRrpq4gbnF67Q8XUQkTiV9u+/Toi0tZLyxhYEP72Dw0028tms4YaNlfyIi8apHhRSACYWwgkGcgRbC9Wm82VrIO21RbaEkIhKHelS779NMQyNlbxRx376v01YYZcqFa5lbWKVNaUVE4kiP/Y1sNQZIf6OKvj/bxGkvtfK3g2cQJeE23xARSWo9NqTg7ztTmFAIV1OI+k+8PBPsx6stGRyMNNtdmoiI0IPbfZ34jtB/QQ7z35tMc3+YeskK7uv9vt1ViYj0eAopwPLX41ncQG+Hk/zzR7JmfDkopEREbNej232dGANRC3dTiOp9xcw5Moxng4Vq/YmI2Egzqc9w7vNR/twAFi37VxqGQuPkN5iR97HdZYmI9EgKqc+w6vyk/M1PLpB2+Xi2XdgXFFIiIrZQSH2B1IZ2llefwbecFkMzP+Ga7O30dWfZXZaISI+hkPoCKTsPcNr/lvFB/giWTxhF9lVt3Oz12V2WiEiPoZD6AladH+cqP+lAftZE9l9WACikRES6i1b3HadMX5jfV03k0upLmXNkmFb9iYh0A82kjpNny8cMDpTQnl3Mc5P6M3LKfvq6FVQiIl1JIXWcrDo/1PlxORxkDZ6IL+zFMkEAbUorItJF9Nv1JOTsi/CTdy5l4nvXcXftaN3mQ0SkiyikTpQxZKz/iKE/C5L3QDp/WTaRXeF0u6sSEUlKavedBMtfD/56nB4P6eeNwRfJpTlai8eRQorDZXd5IiJJQzOpU2FZ5O+M8L2l1zH23W8yyzeOBqvV7qpERJKGQuoUmEiEzFXVDHuohgHzoixYM47DlsPuskREkobafafIagxAYwBndjap/hF8HMkj31lHttNNljPN7vJERBKaQipGTHs7he9FuCPrRqz8MJPP2sL9RasVVCIip0DtvhgxoRCZS3Yw+Kd7GfKzVl7ZPIrGaMTuskREEppmUjEUbWkh2tKCyxhcDV62txfQaurp7XSQ58qwuzwRkYSjkOoCprmF0tVR7jh6E+0FFpMnVPGT4jV4HCl2lyYiklDU7usC0ZYWMhdv5bRH3mfw0y28Xj2cNqPWn4jIiVJIdZFoWxtWYwBXQxNWvYflR3uzts3SFkoiIidA7b4uZhoD9F1SzA8P3UBbYZRrLljL3MIqbUorInIc9Juyi1mNATJer6LssSoGPd/CW/uHEMXYXZaISEJQSHUDE4kQbWvD2dxGY002vw/24fXWNN04UUTkS6jd1518dfR/JZdfbL2a5n6Gr1+8gvt6v293VSIicUsh1Y2shgY8izZS6HDS61/O4t2xA0EhJSLyudTu627GQNTC1dzOh/uLmFs3mOeaCtT6ExE5BoWUTZz7fJT/0cErD1/InJev5Y/BkXaXJCISd9Tus4lV5yflLT+5QPpl49h2QR/I/8juskRE4opCKg6kNoZZXT2I77jbGZrxCZOzd1DmzrK7LBER2ymk4oC7+gCn/aaM7QVnsXTc2WRcHeJmr8/uskREbKeQigNWnR/nKj/pQEHaRPZe1htQSImIaOFEnEmvDfPce+O5YtfF3F83RKv+RKRH00wqzni2fswZT5bSnNOH31eWM3zKQfq6FVQi0jPFfCY1b948xo0bR3Z2NoWFhVx55ZVUV1d3OqetrY3p06dTUFBAVlYWU6ZMoaamJtalJCSrzg/rt5GytIrsPXAonIdlonaXJSJii5iH1IoVK5g+fTpr165lyZIlhMNhvvrVr9LS8v9uUfHd736X1157jZdeeokVK1Zw+PBhrr766liXkvCyD0R4eM0kztv6Ne6uOYtP1PoTkR7GYYzp0i25jxw5QmFhIStWrOD8888nEAjQu3dvnn/+ea655hoAdu7cydChQ1mzZg0TJ0780msGg0G8Xi8XMBl3Et/t1lWQjykpxMr2sGdKOv971VNckK5ZlYgkvmBTlLwz9hAIBMjJyfnc87p84UQgEAAgPz8fgE2bNhEOh6msrOw4Z8iQIZSVlbFmzZpjXiMUChEMBjs9egLLX090+06cGz8g3efEF/HSGm0nbCy7SxMR6RZdGlLRaJQZM2Zw7rnnMnz4cAB8Ph+pqank5uZ2OreoqAif79jLrufNm4fX6+149OvXryvLjjvGssivjjB72dcYs+ZmZvnGUac7/IpID9ClITV9+nS2b9/OCy+8cErXmT17NoFAoONx4MCBGFWYIKIWmauqGfbTWvrPjbLgnXEctlx2VyUi0uW6bAn6rbfeysKFC1m5ciV9+/btOF5cXEx7ezuNjY2dZlM1NTUUFxcf81oejwePx9NVpSYEqzEAjQGc2dl4/CM4EMml2OUny5FChjPV7vJERLpEzGdSxhhuvfVWFixYwLJlyygvL+/0/JgxY0hJSWHp0qUdx6qrq9m/fz8VFRWxLifpmPZ2em+OcPurNzJx6e3M8p1Lc7TN7rJERLpEzGdS06dP5/nnn+eVV14hOzu7430mr9dLeno6Xq+Xm2++mZkzZ5Kfn09OTg633XYbFRUVx7Wyr6czoRCZyz5gyMZsor28vHbrKH4waTlZ2jtERJJQzEPqySefBOCCCy7odPyZZ57hxhtvBOCxxx7D6XQyZcoUQqEQkyZN4le/+lWsS0la0aYmok1NuNrDuOtz2d5eQKupp7fTQZ4rw+7yRERipss/J9UVesrnpL6MMzOTln87E994F+F8i6vHbWRu8To8PfjPREQSw/F+Tkp79yWwaEsLmYu3cvqKdEz/El7JOYsfFa7G41JIiUhy0DsZCS7a1obV0IDTHyTq97CirZD1oTC1+hyViCQBzaSShAkE6fu3Un74yQ209Y5yzQVrmVtYhcuhf4eISOLSb7AkYQWDZLxeRdmjVQx6voXF+4YSQdsniUhiU0glEROJEG1rwxk8SrA2ixebSljc6tHu6SKSsNTuS0a1fvq/ksej266lpa/hPy9eyZzeO+yuSkTkhCmkkpDV0IBn0UaKXS6sc0ewcvTpoJASkQSkdl+yMgYTieAKtvPxgd78xD+I55oKOKjWn4gkEIVUknMe8DHgRfjzo5XMefla/hgcaXdJIiLHTe2+JGfV+Ul9008+kHnJON47vwzyP7K7LBGR46KQ6kFSG9tZu2sgt6a2MjjDx+TsHZS5s+wuS0TkcymkehD3roMMfLY/mwtG8dYYJ56rwtziPWx3WSIin0sh1YNYdX5cb/vJBHq5J/LRJYWgkBKROKaQ6qHSj4R5aetodpX3Zmzufm7I3URftf5EJM5odV8P5dn6MYOejND4P2U8u+hC3m3rY3dJIiL/RDOpHsqq80OdnxSHg5zyiRwO52GZBm1IKyJxRb+RejpjyD4Q4edrKzl/2zXcXXOW9voTkbihmZSQvuEjhhwuxMrK5qUrz+WiKTsocWsHdRGxn0JKsPz14K/HmZJKxoSxHInk0BqtIcXhIsXhsrs8EenB1O6TDsayyN0VYfbyrzF27U3M8o2jTnf4FREbKaTk/4laZK6uZugjdZQ9CAveGcdhSzMpEbGP2n3SidUYgMYAzsxM0o6M5EAkl1KXnwxHChnOVLvLE5EeRiElx2QiEXpti3Db6zdCXjtXnLmVOUWr8DrT7S5NRHoQtfvkmEwoRObSDxj60H4GP3KUVzadTb2lFX8i0r00k5LPFW1qItrUhCsUwl2fS3W4APCT73JpRiUi3UIhJV/KtB6lZK3F7eYmwnkWk8dVMbfoXb1HJSJdTiElXyra2krm4q2cviIdU1bMa5kjuK9wJRkopESka+k9KTku0bY2rIYGnPVNmHoPq9p6sSnUrs9RiUiX0kxKTogJBOm7LMqs2hsJ9Y5y9fnreLBokzamFZEuod8sckKsYJCMRZvp/9hmBj3XwuJ9Q4mgVX8i0jUUUnLCTLidaGsrzkArzTVZvNhUwlutKdo9XURiTu0+OXlH6ilbWMAjO6+ltdTwn5NWMqf3DrurEpEkopCSk2Y1NJC2aBMlTgfWxOGsGDUIFFIiEkNq98mpiVqYSAR3U4h9B3vxaP1A/tTs5aBafyISAwopiQnHwRoGvAh/fHQSP/rLf/LH4Ei7SxKRJKB2n8SE5a8n9c168oGsi8ex6fz+kP+R3WWJSILTTEpiLiXQzvrdA7jzk9HMb+zDfrX+ROQkaSYlMefedZCBz/RnXa9xvDbaCVe+yrdzD9ldlogkIIWUxJxV58f1tp9MoLdzIrsmFYFCSkROgkJKulT6kXYWbDubA0fzGOPdz1Tve/R1Z9ldlogkCL0nJV0qdfsBTv91hCP3D+Q3Cyt5t62P3SWJSALRTEq6lHXkCI4jR0gFvKUVHGwvAAJ2lyUiCUIzKek2WYfCPLHuQs7bejU/qh2hvf5E5EtpJiXdJn3jHob4iohk5/DiFefxlSnvU+LWDuoi8vkUUtJtLH89+Otxud1kjB2PL5JLyPhw4iTF4bK7PBGJQ2r3SbczUUPu7gg/evtqxq6fxt01Y3WHXxE5pi4PqQcffBCHw8GMGTM6jrW1tTF9+nQKCgrIyspiypQp1NTUdHUpEi+iFpnv7GLoI/X0ecDJX1ZNYF8kxe6qRCQOdWlIbdiwgV//+tecddZZnY5/97vf5bXXXuOll15ixYoVHD58mKuvvrorS5E4YzU0YH34EY7395B2xMmhSC4NViut0Xa7SxORONJlIdXc3MzUqVN5+umnycvL6zgeCAT4zW9+w6OPPsqFF17ImDFjeOaZZ3j33XdZu3ZtV5UjccqEI/TaHmHGohsY+/Z07q45h0D0qN1liUic6LKQmj59OpdddhmVlZWdjm/atIlwONzp+JAhQygrK2PNmjVdVY7EKRNuJ2vZToY+fJAzHgnxyobR1Fta8Scif9clq/teeOEFqqqq2LBhwz895/P5SE1NJTc3t9PxoqIifD7fMa8XCoUIhUIdXweDwZjWK/aygkEIBnG15pPSMJjqcAHgJ9/lwutMt7s8EbFRzEPqwIED3HHHHSxZsoS0tLSYXHPevHnMmTMnJteS+GWOtlG8zuJ2x02E8yJMHvsec4veJcOZandpImKTmLf7Nm3aRG1tLaNHj8btduN2u1mxYgWPP/44breboqIi2tvbaWxs7PS6mpoaiouLj3nN2bNnEwgEOh4HDhyIddkSB6KtrWS+tZ3TH/6QIU+28OqOs2g1YbvLEhEbxXwmddFFF7Ft27ZOx77xjW8wZMgQ7rrrLvr160dKSgpLly5lypQpAFRXV7N//34qKiqOeU2Px4PH44l1qRKHoq2t0NqKOy0NR30O77b1pszdQF93hF6uTLvLE5FuFvOQys7OZvjw4Z2OZWZmUlBQ0HH85ptvZubMmeTn55OTk8Ntt91GRUUFEydOjHU5kqCigSB93o5yV/2NhHpZTDlvPXOLNmpnCpEexpZtkR577DGcTidTpkwhFAoxadIkfvWrX9lRisSpaFMTGa9vZsCSFMyQASzqM4w5hesUUiI9jMMYY+wu4kQFg0G8Xi8XMBm3QzsVJDvXoIF8cGcv5n3lJYrdAQanBCnRjRNFElqwKUreGXsIBALk5OR87nnaYFbi3xE/ZQt7Ma/6elpKDddWvsPcoq12VyUi3UAhJXHPagyQtmgTJU4H0QnDWTHidKzCzbgc2h9ZJNnpb7kkhqiFiURwNYc4fCifJxoH8qdmLwd140SRpKaZlCQUx8EaBvxpIH9YcwnB0+HGS5dxd69qu8sSkS6ikJKEYvnrSX2zngKHg+yvjmHjOWWgkBJJWmr3SWIyhtRAO5v3lPF939nMb+zDfrX+RJKOZlKSsFy7D1H++wG803sCr4x0YF25kOm52jJLJJkopCRhWXV+3Mv8ZAPOyAR2TSoChZRIUlFISVJI84d5dftZ1LZlc7Z3P9fnbKGvPvArkvAUUpIUUrfv4/Rf9+Ww93Q2nj+EflfXc112g91licgpUkhJUrDq/Djq/HgAb3EFB8L5gEJKJNFpdZ8knazDYX614QK+smMy9x05k0+06k8kYWkmJUknfeMehtQUE8nK4/krzqfi6t2UuEN2lyUiJ0EhJUnH8teDvx6X203GmPHURrIJmWbcuLTfn0iC0d9YSVrGssjbHea+FVcxbsMNzKoZQ63VYndZInICFFKSvIwh493dDH20gdIH3Ly8YgIfR1LtrkpEToDafZLUrIYGaGjAmZFB2pFRHI7k0eCuJcOZgkc3zBSJewop6RFMOEKvbRFmvjEVR347lw/dxpyiVXid6XaXJiJfQO0+6RFMuJ3MFTsZ+tNDnPFwiFc2jKbOsuwuS0S+hGZS0mNYwSAEg7ia80ipH8KucAEpDj9ep0szKpE4pZCSHsccPUrxeovb3DcRyYswefR7zC16lwynFlWIxBu1+6THiba1kfnWdgY99CFDftHMq9vPotmE7S5LRI5BMynpkaKtrdDaitvjwdHgZUOogH7uRkpdFr1cmXaXJyL/l0JKerRosIk+b0f5XsNNhAosrjp3Aw8WbyDF4bK7NBFB7T7p4aJNTWS8sYUBj27jjN81s2jPmYSNVv2JxAuFlPR4JhQi2tSEM9BKW106r7YU8fZRp3ZPF4kDaveJ/ENdPWWv92bu7utpLTZcW/kOc4u22l2VSI+mkBL5v6zGAGmLNlH6povouKEsHz4Iq3Czdk4XsZH+9ol8WtTChNtxNYfwHcrjV43l/KU5h4Nq/YnYQjMpkWNwHKql/1+yeXb9pTQNhBsvXcbdvartLkukx1FIiRyD5a/H80Y9HoeD3AtHs75iACikRLqd2n0iX8QY3E3tbN3blx/VjuA3gWL2q/Un0m00kxL5Eq49hyn//QCWLT6XurMctE5exG15++wuS6RHUEiJfAmrzo97mZ9swBWawAf/VgIKKZFuoZASOQFp9e0s3nEmN0RSGZV9kGtzttLXnWV3WSJJSyElcgJSduzn9Kf6sj93MGv/5Ux6XRXkhpw6u8sSSVoKKZETYNX5cdT58QC5vSs42F4AKKREuopW94mcpKxPwjy98V+46P0ruO/ImdrrT6QLaCYlcpLSqvYy2F9MJLsXz1/Sh4opuylxh+wuSySpKKRETpJV54c6Py6ni6zhE/BFvITNJzhxaL8/kRjR3ySRU2WiePeGmbNqMuM3TuXu2tHUWi12VyWSFBRSIqfKGDLe3c3QRxspuj+FP789kY8jqXZXJZIU1O4TiQGroQEaGnCmpZFWO5rDkTwCKUdIc7jxOFLsLk8kYSmkRGLIRCIUvB9h5ptTceWHuGLwVn5UuJo8V4bdpYkkJLX7RGLIRCJkLd/J0J8e5vSH2nl5/ViORI3dZYkkLM2kRGLMCgYhGMQV8JJaP4w94XwyHH5ynW6ynGl2lyeSUBRSIl3EtIUo2mBxW8pNRPLDXD5qCw8Wv0OGU4sqRI5Xl7T7Dh06xNe//nUKCgpIT09nxIgRbNy4seN5Ywz33nsvJSUlpKenU1lZya5du7qiFBHbRNvayFyyg0GPfMSQJ1p4bdtZNJuw3WWJJJSYh1RDQwPnnnsuKSkpvPHGG7z//vs88sgj5OXldZzz0EMP8fjjjzN//nzWrVtHZmYmkyZNoq2tLdbliNgq2tKCVVOLs7YBV30KG0IF7Gg/SoPVandpIgnBYYyJ6bu6s2bN4p133mHVqlXHfN4YQ2lpKXfeeSff+973AAgEAhQVFfHss89y3XXXfen3CAaDeL1eLmAybi3vlQTgzM6m5cKhHDnbTajA4qpzNvBg8QZSHC67SxOxRbApSt4ZewgEAuTk5HzueTGfSb366quMHTuWr33taxQWFnL22Wfz9NNPdzy/d+9efD4flZWVHce8Xi8TJkxgzZo1x7xmKBQiGAx2eogkkmhTExmLtzDgkW2c8dtmXv/oTMLGsrsskbgX85Das2cPTz75JIMGDeLNN9/kv//7v7n99tv53e9+B4DP5wOgqKio0+uKioo6nvusefPm4fV6Ox79+vWLddkiXc6EQkSbmnA1NhOqS2dha29WtqEtlES+QMxX90WjUcaOHcvcuXMBOPvss9m+fTvz589n2rRpJ3XN2bNnM3PmzI6vg8GggkoSlmlopOyNIn788VSOFkW59sJ3+XHhZm1KK3IMMf9bUVJSwrBhwzodGzp0KPv37weguLgYgJqamk7n1NTUdDz3WR6Ph5ycnE4PkURlNQZIf6OKPo9t5LSXWvnb4cF2lyQSt2IeUueeey7V1dWdjn344Yf0798fgPLycoqLi1m6dGnH88FgkHXr1lFRURHrckTikolEMOF2XE0hjnzi5elAP15tyeCgbpwo0knM233f/e53Oeecc5g7dy7XXnst69ev56mnnuKpp54CwOFwMGPGDO6//34GDRpEeXk599xzD6WlpVx55ZWxLkckvvmO0P8vOTy18QqaBsDXL1nBfb3ft7sqkbgR85AaN24cCxYsYPbs2fzP//wP5eXl/OxnP2Pq1Kkd5/zgBz+gpaWFW265hcbGRs477zwWL15MWpq2jJGexfLX41ncQG8g78LRrJswABRSIh1i/jmp7qDPSUkycowbQfV3Urlh9FrKUv1MytxNX3eW3WWJdInj/ZyU9u4TiRPOvYcZ+P8N4K0l/0L9mQ6arnyDGXkf212WiK0UUiJxwqrz417mJwdImTyeD/6tBBRS0sMppETikMffzpL3h/GNqJsRWYe4NmerWn/SIymkROJQys4DnPa//diTN5R3KobT6+ogN+TU2V2WSLdTSInEIavOj3O1nzQgL7eC/e29AIWU9Dzah0UkzmV+0s5vq87l4p2XMefIMH3gV3oUzaRE4lza5o85o7GESFYRf7i4jLOnfExft+5HJT2DQkokzll1fqjz43K6yBo2AV8kl7BpwolDm9JK0tNPuEiiMFG8H4eZt+oyJlZdz921o3WbD0l6CimRRGEMGWt2M/RnAXr92MOfl09kVzjd7qpEupTafSIJxGpogIYGHB4P6ReOwRfJpTlaS4rDhUdbhEkS0kxKJBFZFvkfRPj+kusZvepb3OWroMHSYgpJPgopkQRkIhGyVlQz9GEfAx+K8OraMfgsu6sSiT21+0QSlNUYgMYArlwvqf5h7Inkk+usI9vpJsup295IclBIiSQ40xaisMrijswbsfIiTB65mfuLViuoJCmo3SeS4KJtbWQu2cEZD+1hyM9beGXLKJqiEbvLEokJzaREkkC0pQVaWnABrnovVe29GBBtoNRlyHNl2F2eyElTSIkkEdPcQunqKHe2foP2gihXTdzA3OJ1Wp4uCUvtPpEkEm1pIeONLQx8eAeDn27itV3DCRst+5PEpZASSTImFMIKBnEGWgjXp/FmayHvtEW1hZIkJLX7RJKUaWik7I0i7tv3ddoKo0y5cC1zC6u0Ka0kFP20iiQpqzFA+htV9P3ZJk57qZW/HTyDKMbuskROiEJKJImZSAQTCuFqClH/iZdngv14tSVDN06UhKF2n0hP4DtC/wU5zH9vMs39YeolK7iv9/t2VyXypRRSIj2A5a/Hs7iB3g4n+eePZM34clBISQJQu0+kpzAGohbuphDV+4qZc2QYzwYL1fqTuKaZlEgP49zno/y5ASxa9q80DIXGyW8wI+9ju8sSOSaFlEgPY9X5Sfmbn1wg7fLxbLuwLyikJE4ppER6sNSGdpZXn8G3nBZDMz/hmuzt9HVn2V2WSAeFlEgPlrLzAKf9bxkf5I9g+YRRZF/Vxs1en91liXRQSIn0YFadH+cqP+lAftZE9l9WACikJH5odZ+IAJDpC/P7qolcWn0pc44M06o/iQuaSYkIAJ4tHzM4UEJ7djHPTerPyCn76etWUIm9FFIiAvy99UedH5fDQdbgifjCXiwTBNCmtGIb/eSJyD/J2RfhJ+9cysT3ruPu2tG6zYfYRiElIp0ZQ8b6jxj6syB5D6Tzl2UT2RVOt7sq6aHU7hORf2L568Ffj9PjIf28MfgiuTRHa/E4UkhxuOwuT3oQzaRE5PNZFvk7I3xv6XWMffebzPKNo8Fqtbsq6UEUUiLyuUwkQuaqaoY9VMOAeVEWrBnHYcthd1nSg6jdJyJfyGoMQGMAZ3Y2qf4RfBzJI99ZR7bTTZYzze7yJMkppETkuJj2dgrfi3BH1o1Y+WEmn7WF+4tWK6ikS6ndJyLHxYRCZC7ZweCf7mXIz1p5ZfMoGqMRu8uSJKeZlIgct2hLC9GWFlzG4Grwsr29gFZTT2+ngzxXht3lSRJSSInICTPNLZSujnLH0ZtoL7CYPKGKnxSvweNIsbs0STJq94nICYu2tJC5eCunPfI+g59u4fXq4bQZtf4k9hRSInJSom1tWI0BXA1NWPUelh/tzdo2S1soSUyp3Scip8Q0Bui7pJgfHrqBtsIo11ywlrmFVdqUVmIi5j9FlmVxzz33UF5eTnp6Oqeddho//vGPMcZ0nGOM4d5776WkpIT09HQqKyvZtWtXrEsRkW5gNQbIeL2KsseqGPR8C2/tH0IU8+UvFDkOMQ+pn/zkJzz55JP84he/4IMPPuAnP/kJDz30EE888UTHOQ899BCPP/448+fPZ926dWRmZjJp0iTa2tpiXY6IdAMTiRBta8PZ3EZjTTa/D/bh9dY03ThRTpnDfHqKEwP//u//TlFREb/5zW86jk2ZMoX09HT+8Ic/YIyhtLSUO++8k+9973sABAIBioqKePbZZ7nuuuu+9HsEg0G8Xi8XMBm3VhOJxA1XXh6t55xOoDyF5n6Gr1+8gvt6v293WRKHgk1R8s7YQyAQICcn53PPi/lM6pxzzmHp0qV8+OGHAGzZsoXVq1dzySWXALB37158Ph+VlZUdr/F6vUyYMIE1a9Yc85qhUIhgMNjpISLxx2powLNoI4W/WseARW28WzfQ7pIkwcV84cSsWbMIBoMMGTIEl8uFZVk88MADTJ06FQCfzwdAUVFRp9cVFRV1PPdZ8+bNY86cObEuVUS6gjFgLFzN7VTvL2Ju78H099Txr+n76OvOsrs6STAxn0n96U9/4rnnnuP555+nqqqK3/3udzz88MP87ne/O+lrzp49m0Ag0PE4cOBADCsWka7g3Oej/I8OXnn4Qua8fC1/DI60uyRJQDGfSX3/+99n1qxZHe8tjRgxgn379jFv3jymTZtGcXExADU1NZSUlHS8rqamhlGjRh3zmh6PB4/HE+tSRaQLWXV+Ut7ykwukXzaObRf0gfyP7C5LEkzMZ1Ktra04nZ0v63K5iEajAJSXl1NcXMzSpUs7ng8Gg6xbt46KiopYlyMicSC1Mczq6kF859BEnmjoz36t+pPjFPOZ1OWXX84DDzxAWVkZZ555Ju+99x6PPvooN910EwAOh4MZM2Zw//33M2jQIMrLy7nnnnsoLS3lyiuvjHU5IhIH3NUHOO03ZWwvOIul484m4+oQN3uP/R60yKfFPKSeeOIJ7rnnHr7zne9QW1tLaWkp3/rWt7j33ns7zvnBD35AS0sLt9xyC42NjZx33nksXryYtDTdl0YkGVl1fpyr/KQDBWkT2XtZb0AhJV8u5p+T6g76nJRI4opcOIY9/wUjBh5ifN7H3Ji7Uav+eqDj/ZyU9u4TkW7l2foxZzxZSnNOH35fWc7wKQfp69Z7VHJsCikR6VZWnR/q/KQ4HGQPnMihcB6WCWpDWjkm/VSIiG2yD0R4eM0kztv6Ne6uOYtPtOpPPkMzKRGxhzFkrP+IIQcKsbKz+NOUc/jqVdspcUftrkziiEJKRGxj+evBX48zJZX0c8fii3hpjdaQ4nCR4nDZXZ7EAbX7RMR2xrLIr44we9nXGLPmZmb5xlGnO/wKCikRiQdRi8xV1Qz7aS3950ZZ8M44DluaSYnafSISJ6zGADQGcGZn4/GP4EAkl2KXnyxHChnOVLvLE5sopEQkrpj2dnpvjnC790ZMfph/H76VucWryHJqR5qeSO0+EYkrJhQic9kHDHlkP4Mfa+W190bRGI3YXZbYRDMpEYk70aYmok1NuNrDuOtz2d5eQKupp7fTQZ4rw+7ypBsppEQkbpnWVkrWWNxu3UQ43+LqcRuZW7wOj/bs7DEUUiISt6ItLWQu3srpK9Ix/Ut4JecsflS4Go9LIdVT6D0pEYlr0bY2rIYGnP4gUb+HFW2FrA+FqdXnqHoEzaREJCGYQJC+fyvlh5/cQFvvKNdcsJa5hVXamDbJ6f+uiCQEKxgk4/Uqyh6tYtDzLSzeN5QIlt1lSRdTSIlIwjCRCNG2NpzBowRrs3ixqYTFrR7tnp7E1O4TkcRT66f/K3k8uu1aWvoa/vPilczpvcPuqqQLKKREJOFYDQ14Fm2k2OXCOncEK0efDgqppKR2n4gkJmMwkQiuYDsfH+jNT/yDeK6pgINq/SUVhZSIJDTnAR8DXoQ/P1rJnJev5Y/BkXaXJDGkdp+IJDSrzk/qm37ygcxLxvHe+WWQ/5HdZUmMKKREJGmkNrazdtdAbk1tZXCGj8nZOyhzZ9ldlpwChZSIJA33roMMfLY/mwtG8dYYJ56rwtziPWx3WXIKFFIikjSsOj+ut/1kAr3cE/nokkJQSCU0hZSIJKX0I2Fe2jqaXeW9GZu7nxtyN9FXrb+Eo9V9IpKUPFs/ZtCTERr/p4xnF13Iu2197C5JToJmUiKSlKw6P9T5SXE4yCmfyOFwHpZp0Ia0CUb/t0QkuRlD9oEIP19byfnbruHumrO0118C0UxKRJJe+oaPGHK4ECsrm5euPJeLpuygxK0d1BOBQkpEkp7lrwd/Pc6UVDImjOVIJIfWaA0pDhcpDpfd5ckXULtPRHoMY1nk7oowe/nXGLv2Jmb5xlGnO/zGNYWUiPQcUYvM1dUMfaSOsgdhwTvjOGxpJhXP1O4TkR7FagxAYwBnZiZpR0ZyIJJLqctPhiOFDGeq3eXJZyikRKRHMpEIvbZFuO31GyGvnSvO3MqcolV4nel2lyafonafiPRIJhQic+kHDH1oP4MfOcorm86m3tKKv3ijmZSI9FjRpiaiTU24QiHc9blUhwsAP/kul2ZUcUIhJSI9nmk9Sslai9vNTYTzLCaPq2Ju0bt6jyoOKKREpMeLtraSuXgrp69Ix5QV81rmCO4rXEkGCim76T0pEREg2taG1dCAs74JU+9hVVsvNoXa9Tkqm2kmJSLyKSYQpO+yKLNqbyTUO8rV56/jwaJN2pjWJvpTFxH5FCsYJGPRZvo/tplBz7WweN9QImjVn10UUiIin2HC7URbW3EGWmmuyeLFphLeak3R7uk2ULtPROTzHKmnbGEBj+y8ltZSw39OWsmc3jvsrqpHUUiJiHwOq6GBtEWbKHE6sCYOZ8WoQaCQ6lZq94mIfJGohYlEcDeF2HewF4/WD+RPzV4OqvXXLRRSIiLHwXGwhgEvwh8fncSP/vKf/DE40u6SeoQTDqmVK1dy+eWXU1paisPh4K9//Wun540x3HvvvZSUlJCenk5lZSW7du3qdE59fT1Tp04lJyeH3Nxcbr75Zpqb9a8SEYlflr+e1Dc3kv/bNfRZEWFToL/dJfUIJxxSLS0tjBw5kl/+8pfHfP6hhx7i8ccfZ/78+axbt47MzEwmTZpEW1tbxzlTp05lx44dLFmyhIULF7Jy5UpuueWWkx+FiEg3Sgm0s373AO78ZDTzG/uwX62/LuMwxpiTfrHDwYIFC7jyyiuBv8+iSktLufPOO/ne974HQCAQoKioiGeffZbrrruODz74gGHDhrFhwwbGjh0LwOLFi7n00ks5ePAgpaWlX/p9g8EgXq+XC5iM25FysuWLiJwUV68C2of3p61XCrWjncy88lW+nXvI7rISSrApSt4ZewgEAuTk5HzueTF9T2rv3r34fD4qKys7jnm9XiZMmMCaNWsAWLNmDbm5uR0BBVBZWYnT6WTdunXHvG4oFCIYDHZ6iIjYxarz43q7isw/r6P3ZsOuo0V2l5S0YhpSPp8PgKKizv/DioqKOp7z+XwUFhZ2et7tdpOfn99xzmfNmzcPr9fb8ejXr18syxYROWnpR9pZsO1srt1zET/xD9KqvxhLiNV9s2fPJhAIdDwOHDhgd0kiIgCkbj/A6b+OcOT+gfxmYSXvtvWxu6SkEtMP8xYXFwNQU1NDSUlJx/GamhpGjRrVcU5tbW2n10UiEerr6zte/1kejwePxxPLUkVEYsI6cgTHkSOkAt7SCg62FwABu8tKGjGdSZWXl1NcXMzSpUs7jgWDQdatW0dFRQUAFRUVNDY2smnTpo5zli1bRjQaZcKECbEsR0SkW2UdCvPEugs5b+vV/Kh2hPb6i4ETnkk1Nzeze/fujq/37t3L5s2byc/Pp6ysjBkzZnD//fczaNAgysvLueeeeygtLe1YATh06FAuvvhivvnNbzJ//nzC4TC33nor11133XGt7BMRiVfpG/cwxFdEJDuHF684j69MeZ8St3ZQPxUnHFIbN27kK1/5SsfXM2fOBGDatGk8++yz/OAHP6ClpYVbbrmFxsZGzjvvPBYvXkxaWlrHa5577jluvfVWLrroIpxOJ1OmTOHxxx+PwXBEROxj+evBX4/L7SZj7Hh8kVxCxocTJykOl93lJaRT+pyUXfQ5KRGJa04XbZeOYf/lhqzCFi7u/wF39V5NL1em3ZXFDVs+JyUiIkDUIvOdXQx9pJ4+Dzj5y6oJ7IvoH9QnQ7fqEBHpAlZDAzQ04MzIIO3IKA5FchnorsPjcJPhTLW7vIShkBIR6UImHKHX9ggzFt2AIz/E5cO2MadoFV5nut2lJQS1+0REupAJt5O1bCdDHz7IGY+EeGXDaOotrfg7XppJiYh0MSsYhGAQV2s+KQ2DqQ4XAH7yXS7NqL6EQkpEpJuYo20Ur7O43XET4bwIk8e+x9yid/Ue1RdQu09EpJtEW1vJfGs7pz/8IUOebOHVHWfRasJ2lxXXNJMSEelG0dZWaG3FnZaGoz6Hd9t6U+ZuoK87os9RHYNCSkTEBtFAkD5vR7mr/kZCvSymnLeeuUUbtTPFZ6jdJyJig2hTExmvb2bAI1s443fNLNo7jLDRqr/PUkiJiNjEhNuJtrTgDB6l9Ugmr7YU8fZRp3ZP/xS1+0RE7HbET9nCXsyrvp6WUsO1le8wt2ir3VXFBYWUiIjNrMYAaYs2UeJ0EJ0wnBUjTscq3IzLoWaX/gREROJB1MJEIriaQxw+lM8TjQP5U7OXgz289aeZlIhIHHEcrGHAnwbyhzWXEDwdbrx0GXf3qra7LNsopERE4ojlryf1zXoKHA6yvzqGjeeUQQ8OKbX7RETikTGkBtrZvKeM7/vOZn5jH/b3wNafZlIiInHKtfsQ5b8fwDu9J/DKSAfWlQuZnnvA7rK6lUJKRCROWXV+3Mv8ZAPOyAR2TSoChZSIiMSbNH+YV7efRW1bNmd793N9zhb6urPsLqvLKaRERBJA6vZ9nP7rvhz2ns7G84fQ7+p6rstusLusLqeQEhFJAFadH0edHw/gLa7gQDgfSP6Q0uo+EZEEk3U4zK82XMBXdkzmviNnJvVef5pJiYgkmPSNexhSU0wkK4/nrzifiqt3U+IO2V1Wl1BIiYgkGMtfD/56XG43GWPGUxvJJmSaceNKuv3+kms0IiI9iLEs8naHuW/FVYzbcAOzasZQa7XYXVZMKaRERBKVMWS8u5uhjzZQ+oCbl1dM4ONIqt1VxZTafSIiCcxqaICGBpwZGaQdGcXhSB4N7loynCl4HCl2l3fKFFIiIknAhCP02hZh5htTceS3c/nQbcwpWoXXmW53aadE7T4RkSRgwu1krtjJ0J8e4oyHQ7yyYTR1lmV3WadMMykRkSRhBYMQDOJqziOlfgi7wgWkOPx4na6EnVEppEREkow5epTi9Ra3uW8ikhdh8uj3mFv0LhnOxFtUoXafiEiSiba1kfnWdgY99CFDftHMq9vPotmE7S7rpGgmJSKShKKtrdDaitvjwdHgZUOogH7uRkpdFr1cmXaXd9wUUiIiSSwabKLP21G+13AToQKLq87dwIPFG0hxuOwu7bio3SciksSiTU1kvLGFAY9u44zfNbNoz5mETeKs+lNIiYgkORMKEW1qwhlopa0unVdbinj7qDMhdk9Xu09EpKeoq6fs9d7M3X09rcWGayvfYW7RVrur+kIKKRGRHsJqDJC2aBOlb7qIjhvK8uGDsAo3x/XO6fFbmYiIxF7UwoTbcTWH8B3K41eN5fylOYeDcdr600xKRKQHchyqpf9fsnl2/aU0DYQbL13G3b2q7S7rnyikRER6IMtfj+eNejwOB7kXjmZ9xQCIw5BSu09EpCczBndTO1v39uVHtSP4TaCY/XHU+tNMSkSkh3PtOUz57wewbPG51J3loHXyIm7L22d3WYBCSkSkx7Pq/LiX+ckGXKEJfPBvJaCQEhGReJNW387iHWdyQySVUdkHuTZnK33dWbbVc8LvSa1cuZLLL7+c0tJSHA4Hf/3rXzueC4fD3HXXXYwYMYLMzExKS0u54YYbOHz4cKdr1NfXM3XqVHJycsjNzeXmm2+muTl+eqAiIj1Vyo79nP5UhP0/Hsz81yaxrHWArfWccEi1tLQwcuRIfvnLX/7Tc62trVRVVXHPPfdQVVXFyy+/THV1NVdccUWn86ZOncqOHTtYsmQJCxcuZOXKldxyyy0nPwoREYkJq86P490teBZtIHcnHGwvsLUehzHGnPSLHQ4WLFjAlVde+bnnbNiwgfHjx7Nv3z7Kysr44IMPGDZsGBs2bGDs2LEALF68mEsvvZSDBw9SWlr6pd83GAzi9Xq5gMm4HSknW76IiHyB8FfHsvc6GFhWy3m9P+LbeesoiVHrL9gUJe+MPQQCAXJycj73vC5fgh4IBHA4HOTm5gKwZs0acnNzOwIKoLKyEqfTybp167q6HBEROU5pVXsZ/MujOO7vxfOLz2eLDbOqLl040dbWxl133cX111/fkZQ+n4/CwsLORbjd5Ofn4/P5jnmdUChEKBTq+DoYDHZd0SIiAvy99UedH5fTRdbwCfgiXsLmE5w4um2/vy77LuFwmGuvvRZjDE8++eQpXWvevHl4vd6OR79+/WJUpYiIfCkTxbs3zJxVkxm/cSp3146m1mrplm/dJSH1j4Dat28fS5Ys6dRvLC4upra2ttP5kUiE+vp6iouLj3m92bNnEwgEOh4HDhzoirJFRORYjCHj3d0MfbSRovtT+PPbE/k4ktot3zrm7b5/BNSuXbtYvnw5BQWde5gVFRU0NjayadMmxowZA8CyZcuIRqNMmDDhmNf0eDx4PJ5YlyoiIsfJamiAhgacaWmk1Y7mcCSPQMoR0hxuPF24gO2EQ6q5uZndu3d3fL137142b95Mfn4+JSUlXHPNNVRVVbFw4UIsy+p4nyk/P5/U1FSGDh3KxRdfzDe/+U3mz59POBzm1ltv5brrrjuulX0iImIfE4lQ8H6EmW9OxZUf4orBW/lR4WryXBld8v1OeAn622+/zVe+8pV/Oj5t2jT+z//5P5SXlx/zdcuXL+eCCy4A/v5h3ltvvZXXXnsNp9PJlClTePzxx8nKOr6ljVqCLiJiH1dODo48L9G8bHZ+K4s3L32MM1IyT+gax7sE/YRnUhdccAFflGvHk3n5+fk8//zzJ/qtRUQkDljBIASDuAJeUuuHsSecT4bDT67TTZYzLabfS3v3iYjISTFtIYo2WNyWchOR/DCXj9rCg8XvkOGM3aIK3U9KREROSrStjcwlOxj0yEcMeaKF17adRbMJx/R7aCYlIiInLdrSAi0tuJ1OXPVeNoQKGOBuoNRlYrKYQiElIiKnLNrcQunKKN9ruolQgcVV52zgweINpDhcp3RdtftEROSURZuayFi8hQGPbOOM3zbz+kdnEjbWKV9XISUiIjFhQiGiTU24GpsJ1aWzsLU3K9s4pS2U1O4TEZGYMg2NlL1RxI8/nsrRoijXXvguPy7cfFKb0momJSIiMWU1Bkh/o4o+j23ktJda+dvhwSd9LYWUiIjEnIlEMOF2XE0hjnzi5elAP15tyeBgpPmErqN2n4iIdB3fEfr/JYenNl5B0wD4+iUruK/3+8f9coWUiIh0Gctfj2dxA72BvAtHs27CAFBIiYhI3Pi/e7qmBNv54OMS7ss/k1BzGNjzpS9VSImISLdw7j3MwP9vAG8t+RescBuw6Etfo5ASEZFuYdX5cS/zkwNEjnOPv4QMqX/cDiRCGE7oblgiIhIPIvw9pL7s9k4JGVJNTU0ArD6OqaKIiMSvpqYmvF7v5z5/wnfmjQfRaJTDhw9jjKGsrIwDBw584Z0dE1kwGKRfv35JPUbQOJNNTxhnTxgjdN04jTE0NTVRWlqK0/n5H9lNyJmU0+mkb9++BINBAHJycpL6hwR6xhhB40w2PWGcPWGM0DXj/KIZ1D9oxwkREYlbCikREYlbCR1SHo+H++67D4/HY3cpXaYnjBE0zmTTE8bZE8YI9o8zIRdOiIhIz5DQMykREUluCikREYlbCikREYlbCikREYlbCRtSv/zlLxkwYABpaWlMmDCB9evX213SKZk3bx7jxo0jOzubwsJCrrzySqqrqzud09bWxvTp0ykoKCArK4spU6ZQU1NjU8Wn7sEHH8ThcDBjxoyOY8kyxkOHDvH1r3+dgoIC0tPTGTFiBBs3bux43hjDvffeS0lJCenp6VRWVrJr1y4bKz5xlmVxzz33UF5eTnp6Oqeddho//vGPO+3FlojjXLlyJZdffjmlpaU4HA7++te/dnr+eMZUX1/P1KlTycnJITc3l5tvvpnm5hO7I21X+qIxhsNh7rrrLkaMGEFmZialpaXccMMNHD58uNM1um2MJgG98MILJjU11fz2t781O3bsMN/85jdNbm6uqampsbu0kzZp0iTzzDPPmO3bt5vNmzebSy+91JSVlZnm5uaOc7797W+bfv36maVLl5qNGzeaiRMnmnPOOcfGqk/e+vXrzYABA8xZZ51l7rjjjo7jyTDG+vp6079/f3PjjTeadevWmT179pg333zT7N69u+OcBx980Hi9XvPXv/7VbNmyxVxxxRWmvLzcHD161MbKT8wDDzxgCgoKzMKFC83evXvNSy+9ZLKysszPf/7zjnMScZyLFi0yP/zhD83LL79sALNgwYJOzx/PmC6++GIzcuRIs3btWrNq1Spz+umnm+uvv76bR/L5vmiMjY2NprKy0rz44otm586dZs2aNWb8+PFmzJgxna7RXWNMyJAaP368mT59esfXlmWZ0tJSM2/ePBuriq3a2loDmBUrVhhj/v6Dk5KSYl566aWOcz744AMDmDVr1thV5klpamoygwYNMkuWLDH/+q//2hFSyTLGu+66y5x33nmf+3w0GjXFxcXmpz/9acexxsZG4/F4zB//+MfuKDEmLrvsMnPTTTd1Onb11VebqVOnGmOSY5yf/QV+PGN6//33DWA2bNjQcc4bb7xhHA6HOXToULfVfryOFcSftX79egOYffv2GWO6d4wJ1+5rb29n06ZNVFZWdhxzOp1UVlayZs0aGyuLrUAgAEB+fj4AmzZtIhwOdxr3kCFDKCsrS7hxT58+ncsuu6zTWCB5xvjqq68yduxYvva1r1FYWMjZZ5/N008/3fH83r178fl8ncbp9XqZMGFCQo3znHPOYenSpXz44YcAbNmyhdWrV3PJJZcAyTPOTzueMa1Zs4bc3FzGjh3bcU5lZSVOp5N169Z1e82xEAgEcDgc5ObmAt07xoTbYLaurg7LsigqKup0vKioiJ07d9pUVWxFo1FmzJjBueeey/DhwwHw+XykpqZ2/JD8Q1FRET6fz4YqT84LL7xAVVUVGzZs+KfnkmWMe/bs4cknn2TmzJncfffdbNiwgdtvv53U1FSmTZvWMZZj/Qwn0jhnzZpFMBhkyJAhuFwuLMvigQceYOrUqQBJM85PO54x+Xw+CgsLOz3vdrvJz89PyHG3tbVx1113cf3113dsMNudY0y4kOoJpk+fzvbt21m9erXdpcTUgQMHuOOOO1iyZAlpaWl2l9NlotEoY8eOZe7cuQCcffbZbN++nfnz5zNt2jSbq4udP/3pTzz33HM8//zznHnmmWzevJkZM2ZQWlqaVOPsycLhMNdeey3GGJ588klbaki4dl+vXr1wuVz/tOKrpqaG4uJim6qKnVtvvZWFCxeyfPly+vbt23G8uLiY9vZ2GhsbO52fSOPetGkTtbW1jB49GrfbjdvtZsWKFTz++OO43W6KiooSfowAJSUlDBs2rNOxoUOHsn//foCOsST6z/D3v/99Zs2axXXXXceIESP4r//6L7773e8yb948IHnG+WnHM6bi4mJqa2s7PR+JRKivr0+ocf8joPbt28eSJUs63aajO8eYcCGVmprKmDFjWLp0acexaDTK0qVLqaiosLGyU2OM4dZbb2XBggUsW7aM8vLyTs+PGTOGlJSUTuOurq5m//79CTPuiy66iG3btrF58+aOx9ixY5k6dWrHfyf6GAHOPffcf/r4wIcffkj//v0BKC8vp7i4uNM4g8Eg69atS6hxtra2/tPN6lwuF9FoFEiecX7a8YypoqKCxsZGNm3a1HHOsmXLiEajTJgwodtrPhn/CKhdu3bxt7/9jYKCgk7Pd+sYY7oMo5u88MILxuPxmGeffda8//775pZbbjG5ubnG5/PZXdpJ++///m/j9XrN22+/bT755JOOR2tra8c53/72t01ZWZlZtmyZ2bhxo6moqDAVFRU2Vn3qPr26z5jkGOP69euN2+02DzzwgNm1a5d57rnnTEZGhvnDH/7Qcc6DDz5ocnNzzSuvvGK2bt1qJk+eHPdLsz9r2rRppk+fPh1L0F9++WXTq1cv84Mf/KDjnEQcZ1NTk3nvvffMe++9ZwDz6KOPmvfee69jZdvxjOniiy82Z599tlm3bp1ZvXq1GTRoUFwtQf+iMba3t5srrrjC9O3b12zevLnT76NQKNRxje4aY0KGlDHGPPHEE6asrMykpqaa8ePHm7Vr19pd0ikBjvl45plnOs45evSo+c53vmPy8vJMRkaGueqqq8wnn3xiX9Ex8NmQSpYxvvbaa2b48OHG4/GYIUOGmKeeeqrT89Fo1Nxzzz2mqKjIeDwec9FFF5nq6mqbqj05wWDQ3HHHHaasrMykpaWZgQMHmh/+8IedfpEl4jiXL19+zL+L06ZNM8Yc35j8fr+5/vrrTVZWlsnJyTHf+MY3TFNTkw2jObYvGuPevXs/9/fR8uXLO67RXWPUrTpERCRuJdx7UiIi0nMopEREJG4ppEREJG4ppEREJG4ppEREJG4ppEREJG4ppEREJG4ppEREJG4ppEREJG4ppEREJG4ppEREJG4ppEREJG79/+whMb7JPbD3AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "inYNlUH7WJJH"
      },
      "id": "inYNlUH7WJJH"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1UpHoIVrWJTO"
      },
      "id": "1UpHoIVrWJTO",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raise \"error\""
      ],
      "metadata": {
        "id": "Q66P-2r8V3Zp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "284cbf03-8783-4562-9ea1-9c4e75b697e0"
      },
      "id": "Q66P-2r8V3Zp",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "exceptions must derive from BaseException",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0223ecf2daad>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0;34m\"error\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: exceptions must derive from BaseException"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HVGyEEqsV3dm"
      },
      "id": "HVGyEEqsV3dm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZSC7iiCV3gX"
      },
      "id": "gZSC7iiCV3gX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "PvXS5-xVV3jV"
      },
      "id": "PvXS5-xVV3jV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.manythings.org/anki/deu-eng.zip\n",
        "!unzip deu-eng.zip\n",
        "\n",
        "with open(\"deu.txt\") as f:\n",
        "  sentences = f.readlines()"
      ],
      "metadata": {
        "id": "ycQMdkheV3mJ"
      },
      "id": "ycQMdkheV3mJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "NUM_INSTANCES = 10000\n",
        "MAX_SENT_LEN = 10\n",
        "eng_sentences, deu_sentences = [], []\n",
        "eng_words, deu_words = set(), set()\n",
        "for i in tqdm(range(NUM_INSTANCES)):\n",
        "  rand_idx = np.random.randint(len(sentences))\n",
        "  # find only letters in sentences\n",
        "  eng_sent, deu_sent = [\"<sos>\"], [\"<sos>\"]\n",
        "  eng_sent += re.findall(r\"\\w+\", sentences[rand_idx].split(\"\\t\")[0])\n",
        "  deu_sent += re.findall(r\"\\w+\", sentences[rand_idx].split(\"\\t\")[1])\n",
        "\n",
        "  # change to lowercase\n",
        "  eng_sent = [x.lower() for x in eng_sent]\n",
        "  deu_sent = [x.lower() for x in deu_sent]\n",
        "  eng_sent.append(\"<eos>\")\n",
        "  deu_sent.append(\"<eos>\")\n",
        "\n",
        "  if len(eng_sent) >= MAX_SENT_LEN:\n",
        "    eng_sent = eng_sent[:MAX_SENT_LEN]\n",
        "  else:\n",
        "    for _ in range(MAX_SENT_LEN - len(eng_sent)):\n",
        "      eng_sent.append(\"<pad>\")\n",
        "\n",
        "  if len(deu_sent) >= MAX_SENT_LEN:\n",
        "    deu_sent = deu_sent[:MAX_SENT_LEN]\n",
        "  else:\n",
        "    for _ in range(MAX_SENT_LEN - len(deu_sent)):\n",
        "      deu_sent.append(\"<pad>\")\n",
        "\n",
        "  # add parsed sentences\n",
        "  eng_sentences.append(eng_sent)\n",
        "  deu_sentences.append(deu_sent)\n",
        "\n",
        "  # update unique words\n",
        "  eng_words.update(eng_sent)\n",
        "  deu_words.update(deu_sent)\n",
        "\n",
        "eng_words, deu_words = list(eng_words), list(deu_words)\n",
        "\n",
        "# encode each token into index\n",
        "for i in tqdm(range(len(eng_sentences))):\n",
        "  eng_sentences[i] = [eng_words.index(x) for x in eng_sentences[i]]\n",
        "  deu_sentences[i] = [deu_words.index(x) for x in deu_sentences[i]]\n",
        "\n",
        "idx = 10\n",
        "print(eng_sentences[idx])\n",
        "print([eng_words[x] for x in eng_sentences[idx]])\n",
        "print(deu_sentences[idx])\n",
        "print([deu_words[x] for x in deu_sentences[idx]])"
      ],
      "metadata": {
        "id": "i1hHdWv_V5vW"
      },
      "id": "i1hHdWv_V5vW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENG_VOCAB_SIZE = len(eng_words)\n",
        "DEU_VOCAB_SIZE = len(deu_words)\n",
        "NUM_EPOCHS = 10\n",
        "HIDDEN_SIZE = 16\n",
        "EMBEDDING_DIM = 30\n",
        "BATCH_SIZE = 128\n",
        "NUM_HEADS = 2\n",
        "NUM_LAYERS = 3\n",
        "LEARNING_RATE = 1e-2\n",
        "DROPOUT = .3\n",
        "DEVICE = torch.device('cuda')"
      ],
      "metadata": {
        "id": "HU8qoaG0V6VL"
      },
      "id": "HU8qoaG0V6VL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MTDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self):\n",
        "    # import and initialize dataset\n",
        "    self.source = np.array(eng_sentences, dtype = int)\n",
        "    self.target = np.array(deu_sentences, dtype = int)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # get item by index\n",
        "    return self.source[idx], self.target[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    # returns length of data\n",
        "    return len(self.source)\n",
        "\n",
        "np.random.seed(777)   # for reproducibility\n",
        "dataset = MTDataset()\n",
        "NUM_INSTANCES = len(dataset)\n",
        "TEST_RATIO = 0.3\n",
        "TEST_SIZE = int(NUM_INSTANCES * 0.3)\n",
        "\n",
        "indices = list(range(NUM_INSTANCES))\n",
        "\n",
        "test_idx = np.random.choice(indices, size = TEST_SIZE, replace = False)\n",
        "train_idx = list(set(indices) - set(test_idx))\n",
        "train_sampler, test_sampler = SubsetRandomSampler(train_idx), SubsetRandomSampler(test_idx)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size = BATCH_SIZE, sampler = train_sampler)\n",
        "test_loader = torch.utils.data.DataLoader(dataset, batch_size = BATCH_SIZE, sampler = test_sampler)"
      ],
      "metadata": {
        "id": "nHNIm3alW1En"
      },
      "id": "nHNIm3alW1En",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src, tgt = next(iter(train_loader))\n",
        "print(src.shape, tgt.shape)   # (BATCH_SIZE, SEQ_LEN)"
      ],
      "metadata": {
        "id": "BxmBQ0xJW-Jr"
      },
      "id": "BxmBQ0xJW-Jr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_embedding = nn.Embedding(ENG_VOCAB_SIZE, EMBEDDING_DIM)\n",
        "dec_embedding = nn.Embedding(DEU_VOCAB_SIZE, EMBEDDING_DIM)\n",
        "src, tgt = enc_embedding(src), dec_embedding(tgt)\n",
        "print(src.shape, tgt.shape)                # (BATCH_SIZE, SEQ_LEN, EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "jpLHPKVBXL4A"
      },
      "id": "jpLHPKVBXL4A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## source: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "raxIOgWyXOIo"
      },
      "id": "raxIOgWyXOIo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pe = PositionalEncoding(EMBEDDING_DIM, max_len = MAX_SENT_LEN)\n",
        "src, tgt = pe(src.permute(1, 0, 2)), pe(tgt.permute(1, 0, 2))\n",
        "print(src.shape, tgt.shape)              # (SEQ_LEN, BATCH_SIZE, EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "y_Hq7knTXWWP"
      },
      "id": "y_Hq7knTXWWP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_layer = nn.TransformerEncoderLayer(EMBEDDING_DIM, NUM_HEADS, HIDDEN_SIZE, DROPOUT)\n",
        "memory = enc_layer(src)\n",
        "print(memory.shape)                      # (SEQ_LEN, BATCH_SIZE, EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "t6wplf9gXZGI"
      },
      "id": "t6wplf9gXZGI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = nn.TransformerEncoder(enc_layer, num_layers = NUM_LAYERS)\n",
        "memory = encoder(src)\n",
        "print(memory.shape)                     # (SEQ_LEN, BATCH_SIZE, EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "FYVuRta7XbO5"
      },
      "id": "FYVuRta7XbO5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dec_layer = nn.TransformerDecoderLayer(EMBEDDING_DIM, NUM_HEADS, HIDDEN_SIZE, DROPOUT)\n",
        "decoder = nn.TransformerDecoder(dec_layer, num_layers = NUM_LAYERS)\n",
        "transformer_output = decoder(tgt, memory)\n",
        "print(transformer_output.shape)        # (SEQ_LEN, BATCH_SIZE, EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "LX-BFeg4Xfo4"
      },
      "id": "LX-BFeg4Xfo4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense = nn.Linear(EMBEDDING_DIM, DEU_VOCAB_SIZE)\n",
        "final_output = dense(transformer_output)\n",
        "print(final_output.shape)             # (SEQ_LEN, BATCH_SIZE, EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "dhYYhVzDXk7j"
      },
      "id": "dhYYhVzDXk7j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerNet(nn.Module):\n",
        "  def __init__(self, num_src_vocab, num_tgt_vocab, embedding_dim, hidden_size, nheads, n_layers, max_src_len, max_tgt_len, dropout):\n",
        "    super(TransformerNet, self).__init__()\n",
        "    # embedding layers\n",
        "    self.enc_embedding = nn.Embedding(num_src_vocab, embedding_dim)\n",
        "    self.dec_embedding = nn.Embedding(num_tgt_vocab, embedding_dim)\n",
        "\n",
        "    # positional encoding layers\n",
        "    self.enc_pe = PositionalEncoding(embedding_dim, max_len = max_src_len)\n",
        "    self.dec_pe = PositionalEncoding(embedding_dim, max_len = max_tgt_len)\n",
        "\n",
        "    # encoder/decoder layers\n",
        "    enc_layer = nn.TransformerEncoderLayer(embedding_dim, nheads, hidden_size, dropout)\n",
        "    dec_layer = nn.TransformerDecoderLayer(embedding_dim, nheads, hidden_size, dropout)\n",
        "    self.encoder = nn.TransformerEncoder(enc_layer, num_layers = n_layers)\n",
        "    self.decoder = nn.TransformerDecoder(dec_layer, num_layers = n_layers)\n",
        "\n",
        "    # final dense layer\n",
        "    self.dense = nn.Linear(embedding_dim, num_tgt_vocab)\n",
        "    self.log_softmax = nn.LogSoftmax()\n",
        "\n",
        "  def forward(self, src, tgt):\n",
        "    src, tgt = self.enc_embedding(src).permute(1, 0, 2), self.dec_embedding(tgt).permute(1, 0, 2)\n",
        "    src, tgt = self.enc_pe(src), self.dec_pe(tgt)\n",
        "    memory = self.encoder(src)\n",
        "    transformer_out = self.decoder(tgt, memory)\n",
        "    final_out = self.dense(transformer_out)\n",
        "    return self.log_softmax(final_out)"
      ],
      "metadata": {
        "id": "BqUpJEdzXnHv"
      },
      "id": "BqUpJEdzXnHv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerNet(ENG_VOCAB_SIZE, DEU_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_SIZE, NUM_HEADS, NUM_LAYERS, MAX_SENT_LEN, MAX_SENT_LEN, DROPOUT).to(DEVICE)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "metadata": {
        "id": "wVRe3n8jXowv"
      },
      "id": "wVRe3n8jXowv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "loss_trace = []\n",
        "for epoch in tqdm(range(NUM_EPOCHS)):\n",
        "  current_loss = 0\n",
        "  for i, (x, y) in enumerate(train_loader):\n",
        "    x, y  = x.to(DEVICE), y.to(DEVICE)\n",
        "    outputs = model(x, y)\n",
        "    loss = criterion(outputs.permute(1, 2, 0), y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    current_loss += loss.item()\n",
        "  loss_trace.append(current_loss)\n",
        "\n"
      ],
      "metadata": {
        "id": "BA0ibMQkXrWs"
      },
      "id": "BA0ibMQkXrWs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss curve\n",
        "plt.plot(range(1, NUM_EPOCHS+1), loss_trace, 'r-')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vXy1cqa-X7-H"
      },
      "id": "vXy1cqa-X7-H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6RCEa9E9Yy6v"
      },
      "id": "6RCEa9E9Yy6v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/1706.03762\n",
        "https://buomsoo-kim.github.io/attention/2020/04/19/Attention-mechanism-17.md/\n",
        "https://buomsoo-kim.github.io/attention/2020/04/20/Attention-mechanism-18.md/\n",
        "https://buomsoo-kim.github.io/attention/2020/04/21/Attention-mechanism-19.md/\n",
        "https://towardsdatascience.com/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
        "https://nlp.seas.harvard.edu/annotated-transformer/\n",
        "https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "https://d2l.ai/chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html\n",
        "\n"
      ],
      "metadata": {
        "id": "vQypvqNHYw_x"
      },
      "id": "vQypvqNHYw_x"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DQJYoOT6rZpd"
      },
      "id": "DQJYoOT6rZpd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N-ayEiAAYrO3"
      },
      "id": "N-ayEiAAYrO3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}